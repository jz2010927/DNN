{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, matplotlib.pyplot as plt, multiprocessing as mp\n",
    "from numpy import random\n",
    "import torch, cv2, time, random, os, threading, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE = {\n",
    "    'boolean': torch.bool, 'ui8': torch.uint8, 'i8': torch.int8, 'i16': torch.int16, 'i32': torch.int32, 'i64': torch.int64, \n",
    "    'f16': torch.float16, 'f32': torch.float32, 'f64': torch.float64, 'f64Complex': torch.complex64, 'f128Complex': torch.complex128\n",
    "}\n",
    "DEVICE = {\n",
    "    'auto': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"), \n",
    "    'cpu': torch.device('cpu'), \n",
    "    'cuda0': torch.device('cuda:0')\n",
    "}\n",
    "\n",
    "DEVICE_CHOICE = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(object):\n",
    "    def __init__(self, layers=(10, 20, 10), aFunc=('cos', 'PRelu', 'PRelu', 'sin')):\n",
    "        self.layerNum = len(layers)\n",
    "        assert self.layerNum >= 1\n",
    "        torch.manual_seed(0)\n",
    "        self.backProp = {\n",
    "            'PRelu': True,  # 如果False, 则 == Leaky Relu\n",
    "            'Norm': [True] * self.layerNum\n",
    "        }\n",
    "        self.paramLimits = {\n",
    "            'weights': (-100000, 100000), \n",
    "            'biases': (-100000, 100000), \n",
    "            'relu param': (-100, 100), \n",
    "            'BN gamma': (-1000, 1000), \n",
    "            'BN beta': (-1000, 1000), \n",
    "            'dW': (-1, 1), \n",
    "            'dB': (-10, 10), \n",
    "            'dReluP': (-10, 10), \n",
    "            'dGamma': (-10, 10), \n",
    "            'dBeta': (-10, 10)\n",
    "        }\n",
    "        self.layerShapes = layers\n",
    "        self.aFuncChosen = aFunc\n",
    "        self.defaultLr = 0.0001\n",
    "        self.lr = {\n",
    "            'weight': self.defaultLr * 250,\n",
    "            'bias': self.defaultLr * 5000,\n",
    "            'relu param': self.defaultLr * 10, \n",
    "            'BN gamma': self.defaultLr, \n",
    "            'BN beta': self.defaultLr\n",
    "        }\n",
    "        self.inputs = None\n",
    "        self.targetY = None\n",
    "        self.weights = [None] * self.layerNum\n",
    "        self.biases = [None] * self.layerNum\n",
    "        self.reluParam = [0.01] * self.layerNum\n",
    "        self.layers = {\n",
    "            'Z': [None] * self.layerNum, \n",
    "            'N': [None] * self.layerNum, \n",
    "            'A': [None] * self.layerNum\n",
    "        }\n",
    "        self.BN = {\n",
    "            'epsilon': 1e-5, \n",
    "            'gamma': [1] * self.layerNum, \n",
    "            'beta': [0] * self.layerNum, \n",
    "            'cache': [None] * self.layerNum\n",
    "        }\n",
    "        self.activFunc = {\n",
    "            'PRelu': lambda x, i: torch.max(x, x * self.reluParam[i]), \n",
    "            'sigmoid': lambda x: 1/(1+torch.exp(-x)), \n",
    "            'softmax': lambda x: torch.exp(x - torch.max(x)) / torch.sum(torch.exp(x - torch.max(x))), \n",
    "            'tanh': lambda x: torch.tanh(x), \n",
    "            'sin': lambda x: torch.sin(x), \n",
    "            'cos': lambda x: torch.cos(x), \n",
    "            'linear': lambda x: x\n",
    "        }\n",
    "        self.activFuncDer = {\n",
    "            'PRelu': self._PReluDer,  \n",
    "            'sigmoid': lambda x: self.activFunc['sigmoid'](x) * (1 - self.activFunc['sigmoid'](x)), \n",
    "            'softmax': lambda x, a: self.activFunc['softmax'](x) * (a - self.activFunc['softmax'](x)), \n",
    "            'tanh': lambda x: 1 - torch.tanh(x) ** 2, \n",
    "            'sin': lambda x: torch.cos(x), \n",
    "            'cos': lambda x: -torch.sin(x), \n",
    "            'linear': lambda x: 1\n",
    "        }\n",
    "        self.lossFunc = {\n",
    "            'mse': lambda predictY, targetY: (targetY - predictY) ** 2, \n",
    "            'bce': lambda predictY, targetY: targetY * torch.log(predictY) + (1 - targetY) * torch.log(1 - predictY)\n",
    "        }\n",
    "        self.lossFuncDer = {\n",
    "            'mse': lambda predictY, targetY: 2 * (targetY - predictY), \n",
    "            'bce': lambda predictY, targetY: Y / predictY + (targetY - 1) / (1 - predictY)\n",
    "        }\n",
    "    \n",
    "    def _dA_dReluP(self, x, i):\n",
    "        data = x.clone()\n",
    "        data[data > 0] = 0\n",
    "        data[data <= 0] = torch.mean(data[data <= 0])\n",
    "        return data\n",
    "    \n",
    "    def _PReluDer(self, x, i): \n",
    "        data = x.clone()\n",
    "        data[data > 0] = 1\n",
    "        data[data <= 0] = self.reluParam[i]\n",
    "        return data\n",
    "    \n",
    "    def setBackProp(self, **kwargs):\n",
    "        '''\n",
    "        Keys: PRelu, Norm\n",
    "        Values: True, (True, False ..)\n",
    "        '''\n",
    "        for k, v in kwargs.items():\n",
    "            try:\n",
    "                self.backProp[k] = v\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    def batchNorm(self, x, layerIter):\n",
    "        mean = torch.mean(x)\n",
    "        variance = torch.mean((x - mean) ** 2)\n",
    "        # normalize\n",
    "        fenzi = (x - mean) * 1.0\n",
    "        fenmu = torch.sqrt(variance + self.BN['epsilon'])\n",
    "        # * 1.0 是转换成float\n",
    "        xNorm = fenzi / fenmu\n",
    "        cache = {\n",
    "            'BNmean': mean, \n",
    "            'BNvariance': variance, \n",
    "            'BNfenzi': fenzi, \n",
    "            'BNfenmu': fenmu\n",
    "        }\n",
    "        self.BN['cache'][layerIter] = cache\n",
    "        return self.BN['gamma'][layerIter] * xNorm + self.BN['beta'][layerIter]\n",
    "    \n",
    "    def setToLimit(self, data, limits):\n",
    "        x = data.clone()\n",
    "        x[x<limits[0]] = limits[0]\n",
    "        x[x>limits[1]] = limits[1]\n",
    "        return x\n",
    "    \n",
    "    # 生成 w、b, 以x的形状是 m x 1\n",
    "    def genParam(self, inputRow):\n",
    "        column = inputRow\n",
    "        for i, r in enumerate(self.layerShapes):\n",
    "#             print('row: ', row, '\\ncolumn: ', column)\n",
    "            self.weights[i] = torch.ones(r, column, dtype=DTYPE['f64'], device=DEVICE[DEVICE_CHOICE])\n",
    "            self.biases[i] = torch.zeros(r, 1, dtype=DTYPE['f64'], device=DEVICE[DEVICE_CHOICE])\n",
    "            column = r\n",
    "\n",
    "    # 前向传播函数\n",
    "    def forward(self, x):\n",
    "        inputs = x\n",
    "#         print('inputs.shape: ', inputs.shape)\n",
    "        for i in range(self.layerNum):\n",
    "#             print(f'w[{i}].shape: ', self.weights[i].shape)\n",
    "#             print(f'b[{i}].shape: ', self.biases[i].shape)\n",
    "            layerNameFirst = 'N' if self.backProp['Norm'][i] else 'Z'\n",
    "            self.layers['Z'][i] = self.weights[i] @ inputs + self.biases[i]\n",
    "            self.layers['N'][i] = self.batchNorm(self.layers['Z'][i], i)\n",
    "            if self.aFuncChosen[i] == 'PRelu':\n",
    "                self.layers['A'][i] = self.activFunc[self.aFuncChosen[i]](self.layers[layerNameFirst][i], i)\n",
    "            else:\n",
    "                self.layers['A'][i] = self.activFunc[self.aFuncChosen[i]](self.layers[layerNameFirst][i])\n",
    "            inputs = self.layers['A'][i]\n",
    "#             print(f'layer[{i}].shape: ', self.layers['A'][i].shape)\n",
    "    \n",
    "    # 反向传播函数\n",
    "    # input = x, Z = W @ input + b, N = batchNormalize(Z), Y_preditc = activateFunc(N), L = lossFunc(Y_predict)\n",
    "    # 根据链式法则 dL / dW = (dL / dY_predict) * (dY_predict / dN) * (dN / dZ) * (dZ / dW)\n",
    "    # dL / dY_predict = lossFunc_Der, dY_predict / dN = activateFunc_Der, dN/dZ = gamma/sqrt(variance+epsilon), dZ/dW = input\n",
    "    # ==> dL / dW = lossFunc_Der(Y_predict) * activateFunc_Der(Z) * gamma/sqrt(variance+epsilon) * input\n",
    "    # 同理可证 dL / db = lossFunc_Der(Y_predict) * activateFunc_Der(Z) * gamma/sqrt(variance+epsilon) * 1\n",
    "    def backprop(self):\n",
    "        '''\n",
    "        尚未完成\n",
    "        '''\n",
    "            \n",
    "        dW = [None] * self.layerNum\n",
    "        dB = [None] * self.layerNum\n",
    "        dReluP = [None] * self.layerNum\n",
    "        dGamma = [None] * self.layerNum\n",
    "        dBeta = [None] * self.layerNum\n",
    "        dActivation = [None] * self.layerNum\n",
    "        \n",
    "        dL_Div_dYtrain = self.lossFuncDer['mse'](self.layers['A'][-1], self.targetY)\n",
    "        \n",
    "        for i in reversed(range(self.layerNum)):\n",
    "#             print('i: ', i)\n",
    "            layerNameFirst = 'N' if self.backProp['Norm'][i] else 'Z'\n",
    "            if self.aFuncChosen[i] == 'PRelu':\n",
    "                dActivation[i] = self.activFuncDer[self.aFuncChosen[i]](self.layers[layerNameFirst][i], i)\n",
    "            else:\n",
    "                dActivation[i] = self.activFuncDer[self.aFuncChosen[i]](self.layers[layerNameFirst][i])\n",
    "#             print(f'weight[{i}] shape: {self.weights[i].shape} \\nbias[{i}] shape: {self.biases[i].shape} \\n')\n",
    "            if i == self.layerNum - 1:\n",
    "                dBeta[i] = dB[i] = dL_Div_dYtrain * dActivation[i]\n",
    "                dGamma[i] = dBeta[i] * (self.BN['cache'][i]['BNfenzi'] / self.BN['cache'][i]['BNfenmu'])\n",
    "                if self.backProp['Norm'][i]:\n",
    "                    dB[i] *= self.BN['gamma'][i] / self.BN['cache'][i]['BNfenmu']\n",
    "                if self.backProp['PRelu']:\n",
    "                    dReluP[i] = torch.mean(dL_Div_dYtrain * self.layers[layerNameFirst][i])\n",
    "                dW[i] = dB[i] @ torch.transpose(self.layers['A'][i-1], 0, 1)\n",
    "            else:\n",
    "                dB[i] = (torch.transpose(self.weights[i+1], 0, 1) @ dB[i+1]) * dActivation[i]\n",
    "                dW[i] = dB[i] @ torch.transpose(self.layers['A'][i-1], 0, 1)\n",
    "                dBeta[i] = torch.transpose(self.weights[i+1], 0, 1) @ (dBeta[i+1] * (self.BN['gamma'][i+1] / self.BN['cache'][i+1]['BNfenmu']))\n",
    "                dGamma[i] = dBeta[i] * (self.BN['cache'][i]['BNfenzi'] / self.BN['cache'][i]['BNfenmu'])\n",
    "                if self.backProp['PRelu']:\n",
    "                    dReluP[i] = torch.mean(torch.transpose(self.weights[i], 0, 1) @ dB[i] * self.layers[layerNameFirst][i-1])\n",
    "                    \n",
    "#             print(f'dReluP[{i}]: {dReluP[i]}')\n",
    "            dB_Limited = self.setToLimit(dB[i], self.paramLimits['dB'])\n",
    "            dW_Limited = self.setToLimit(dW[i], self.paramLimits['dW'])\n",
    "        \n",
    "            self.biases[i] += dB_Limited * self.lr['bias']\n",
    "            self.weights[i] += dW_Limited * self.lr['weight']\n",
    "            \n",
    "#             self.biases[i] = self.setToLimit(self.biases[i], self.paramLimits['biases'])\n",
    "#             self.weights[i] = self.setToLimit(self.weights[i], self.paramLimits['weights'])\n",
    "            \n",
    "            if self.aFuncChosen[i] == 'PRelu' and self.backProp['PRelu']:\n",
    "                dReluP_Limited = self.setToLimit(dReluP[i], self.paramLimits['dReluP']).item()\n",
    "                self.reluParam[i] += dReluP_Limited * self.lr['relu param']\n",
    "#                 print('PRelu back proped')\n",
    "            if self.backProp['Norm'][i]:\n",
    "                dBeta_Limited = torch.mean(self.setToLimit(dBeta[i], self.paramLimits['dBeta'])).item()\n",
    "                dGamma_Limited = torch.mean(self.setToLimit(dGamma[i], self.paramLimits['dGamma'])).item()\n",
    "                self.BN['beta'][i] += dBeta_Limited * self.lr['BN gamma']\n",
    "                self.BN['gamma'][i] += dGamma_Limited * self.lr['BN beta']\n",
    "#                 print('BN back proped')\n",
    "#             print(self.reluParam)\n",
    "            \n",
    "    def train(self, inputs, targetY, nanInvestigate=40, epoch = 1000):\n",
    "        self.targetY = targetY\n",
    "        self.inputs = inputs\n",
    "        for e in range(epoch):\n",
    "            self.forward(inputs)\n",
    "            loss = torch.norm(self.layers['A'][-1] - self.targetY)\n",
    "            print(e, f': loss = {loss}')\n",
    "            if loss < 5.0 or e > int(epoch/2):\n",
    "                for k,v in self.lr.items():\n",
    "                    self.lr[k] /= 2\n",
    "            if loss < 2.0 or e > int(epoch*0.9):\n",
    "                for k,v in self.lr.items():\n",
    "                    self.lr[k] /= 5\n",
    "            if loss < 1.0 or torch.isnan(loss):\n",
    "                return\n",
    "#                 print(f'{i} Loss: ', torch.mean(self.lossFunc['mse'](self.layers['A'][-1], self.targetY)).item())\n",
    "#                 print(epoch/100, ': \\n', torch.transpose(self.layers['A'][-1], 0, 1))\n",
    "            self.backprop()\n",
    "            if e > nanInvestigate and nanInvestigate > 0:\n",
    "                self.saveParams('d:\\\\nanInvest_'+str(e)+'.pt', True)\n",
    "                \n",
    "    def printShape(self):\n",
    "        for i in range(self.layerNum):\n",
    "            print(f'weight[{i}] shape: ', self.weights[i].shape)\n",
    "            print(f'bias[{i}] shape: ', self.biases[i].shape)\n",
    "            print(f'Relu Params[{i}]: ', self.reluParam[i])\n",
    "            print(f'BN gamma[{i}]: ', self.BN['gamma'][i])\n",
    "            print(f'BN beta[{i}]: ', self.BN['beta'][i])\n",
    "#             print(f'Z layer shape: ', self.layers['Z'][i].shape)\n",
    "#             print(f'N layer shape: ', self.layers['N'][i].shape)\n",
    "#             print(f'A layer shape: ', self.layers['A'][i].shape)\n",
    "    \n",
    "    def saveParams(self, PATH, layers=False, reluParam=False, BN=False):\n",
    "        params = {\n",
    "            'weight': self.weights, \n",
    "            'bias': self.biases\n",
    "        }\n",
    "        if layers:\n",
    "            params['layers'] = self.layers\n",
    "        if reluParam:\n",
    "            params['reluParam'] = self.reluParam\n",
    "        if BN:\n",
    "            params['BN'] = self.BN\n",
    "        torch.save(params, PATH)\n",
    "        \n",
    "    def readParams(self, PATH, layers=False, reluParam=False, BN=False):\n",
    "        params = torch.load(PATH)\n",
    "        self.weights = params['weight']\n",
    "        self.biases = params['bias']\n",
    "        if layers:\n",
    "            self.layers = params['layers']\n",
    "        if reluParam:\n",
    "            self.reluParam = params['reluParam']\n",
    "        if BN:\n",
    "            self.BN = params['BN']\n",
    "    \n",
    "    # 预测\n",
    "    def predict(self, x):\n",
    "        self.forward(x)\n",
    "        predictY = self.layers['A'][-1]\n",
    "        print('output: ', predictY.squeeze())\n",
    "        return predictY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : loss = 190.03899605849998\n",
      "1 : loss = 66.87714211527951\n",
      "2 : loss = 66.7957636900456\n",
      "3 : loss = 66.82044455752948\n",
      "4 : loss = 66.75295269744228\n",
      "5 : loss = 66.77860008221977\n",
      "6 : loss = 66.70776912667266\n",
      "7 : loss = 66.73435151418718\n",
      "8 : loss = 66.66006518786412\n",
      "9 : loss = 66.68755122449812\n",
      "10 : loss = 66.60968768859195\n",
      "11 : loss = 66.63804380232668\n",
      "12 : loss = 66.5564754623983\n",
      "13 : loss = 66.58566569498103\n",
      "14 : loss = 66.50025895648976\n",
      "15 : loss = 66.53024477459473\n",
      "16 : loss = 66.44085983091603\n",
      "17 : loss = 65.90048898468653\n",
      "18 : loss = 65.91034756068929\n",
      "19 : loss = 65.8842656708442\n",
      "20 : loss = 65.88181485153825\n",
      "21 : loss = 65.88003623879337\n",
      "22 : loss = 65.87949317878481\n",
      "23 : loss = 65.87914032755346\n",
      "24 : loss = 65.87899197895833\n",
      "25 : loss = 65.87891830430645\n",
      "26 : loss = 65.87888152050833\n",
      "27 : loss = 65.87886313123083\n",
      "28 : loss = 65.87885393695298\n",
      "29 : loss = 65.87885301753657\n",
      "0 : loss = 275.3758587128453\n",
      "1 : loss = 275.3755353461734\n",
      "2 : loss = 275.37521198071585\n",
      "3 : loss = 275.3748886164724\n",
      "4 : loss = 275.37456525344317\n",
      "5 : loss = 275.3742418916282\n",
      "6 : loss = 275.373918525858\n",
      "7 : loss = 275.3735951768101\n",
      "8 : loss = 275.3732718082991\n",
      "9 : loss = 275.3729484616795\n",
      "10 : loss = 275.3726251059355\n",
      "11 : loss = 275.37230174623636\n",
      "12 : loss = 275.37197839292077\n",
      "13 : loss = 275.37165504081935\n",
      "14 : loss = 275.37133168993205\n",
      "15 : loss = 275.3710083402589\n",
      "16 : loss = 275.37068499696926\n",
      "17 : loss = 275.37052332329375\n",
      "18 : loss = 275.3704424814253\n",
      "19 : loss = 275.3704020631103\n",
      "20 : loss = 275.3703818591307\n",
      "21 : loss = 275.3703717519738\n",
      "22 : loss = 275.3703666983959\n",
      "23 : loss = 275.3703641741917\n",
      "24 : loss = 275.37036291208966\n",
      "25 : loss = 275.37036227586935\n",
      "26 : loss = 275.37036196034387\n",
      "27 : loss = 275.3703618025811\n",
      "28 : loss = 275.3703617236997\n",
      "29 : loss = 275.3703617106423\n",
      "0 : loss = 520.8323274982591\n",
      "1 : loss = 520.8323275025041\n",
      "2 : loss = 520.8323274971558\n",
      "3 : loss = 520.8323274950051\n",
      "4 : loss = 520.8323274928546\n",
      "5 : loss = 520.832327490704\n",
      "6 : loss = 520.8323274885533\n",
      "7 : loss = 520.8323274864027\n",
      "8 : loss = 520.8323274842521\n",
      "9 : loss = 520.8323274821016\n",
      "10 : loss = 520.832327479951\n",
      "11 : loss = 520.8323274778004\n",
      "12 : loss = 520.8323274756498\n",
      "13 : loss = 520.8323274734992\n",
      "14 : loss = 520.8323274713485\n",
      "15 : loss = 520.8323274660003\n",
      "16 : loss = 520.8323274702452\n",
      "17 : loss = 520.8323274627743\n",
      "18 : loss = 520.8323274654344\n",
      "19 : loss = 520.8323274651657\n",
      "20 : loss = 520.8323274650312\n",
      "21 : loss = 520.832327464964\n",
      "22 : loss = 520.8323274649304\n",
      "23 : loss = 520.8323274649136\n",
      "24 : loss = 520.8323274617073\n",
      "25 : loss = 520.832327464901\n",
      "26 : loss = 520.832327464899\n",
      "27 : loss = 520.8323274648978\n",
      "28 : loss = 520.8323274616995\n",
      "29 : loss = 520.8323274616995\n",
      "0 : loss = 608.4136001772554\n",
      "1 : loss = 608.4136001772554\n",
      "2 : loss = 608.4136001772554\n",
      "3 : loss = 608.4136001772554\n",
      "4 : loss = 608.4136001772554\n",
      "5 : loss = 608.4136001772554\n",
      "6 : loss = 608.4136001772554\n",
      "7 : loss = 608.4136001772554\n",
      "8 : loss = 608.4136001772554\n",
      "9 : loss = 608.4136001772553\n",
      "10 : loss = 608.4136001772553\n",
      "11 : loss = 608.4136001772553\n",
      "12 : loss = 608.4136001772553\n",
      "13 : loss = 608.4136001772553\n",
      "14 : loss = 608.4136001772553\n",
      "15 : loss = 608.4136001772553\n",
      "16 : loss = 608.4136001772553\n",
      "17 : loss = 608.4136001772553\n",
      "18 : loss = 608.4136001772553\n",
      "19 : loss = 608.4136001772553\n",
      "20 : loss = 608.4136001772553\n",
      "21 : loss = 608.4136001772553\n",
      "22 : loss = 608.4136001772553\n",
      "23 : loss = 608.4136001772553\n",
      "24 : loss = 608.4136001772553\n",
      "25 : loss = 608.4136001772553\n",
      "26 : loss = 608.4136001772553\n",
      "27 : loss = 608.4136001772553\n",
      "28 : loss = 608.4136001772553\n",
      "29 : loss = 608.4136001772553\n",
      "0 : loss = 771.1963785192931\n",
      "1 : loss = 771.1963785192931\n",
      "2 : loss = 771.1963785192931\n",
      "3 : loss = 771.1963785192931\n",
      "4 : loss = 771.1963785192931\n",
      "5 : loss = 771.1963785192931\n",
      "6 : loss = 771.1963785192931\n",
      "7 : loss = 771.1963785192931\n",
      "8 : loss = 771.1963785192931\n",
      "9 : loss = 771.1963785192931\n",
      "10 : loss = 771.1963785192931\n",
      "11 : loss = 771.1963785192931\n",
      "12 : loss = 771.1963785192931\n",
      "13 : loss = 771.1963785192931\n",
      "14 : loss = 771.1963785192931\n",
      "15 : loss = 771.1963785192931\n",
      "16 : loss = 771.1963785192931\n",
      "17 : loss = 771.1963785192931\n",
      "18 : loss = 771.1963785192931\n",
      "19 : loss = 771.1963785192931\n",
      "20 : loss = 771.1963785192931\n",
      "21 : loss = 771.1963785192931\n",
      "22 : loss = 771.1963785192931\n",
      "23 : loss = 771.1963785192931\n",
      "24 : loss = 771.1963785192931\n",
      "25 : loss = 771.1963785192931\n",
      "26 : loss = 771.1963785192931\n",
      "27 : loss = 771.1963785192931\n",
      "28 : loss = 771.1963785192931\n",
      "29 : loss = 771.1963785192931\n",
      "0 : loss = 848.3815653931373\n",
      "1 : loss = 848.3815653931373\n",
      "2 : loss = 848.3815653931373\n",
      "3 : loss = 848.3815653931373\n",
      "4 : loss = 848.3815653931373\n",
      "5 : loss = 848.3815653931373\n",
      "6 : loss = 848.3815653931373\n",
      "7 : loss = 848.3815653931373\n",
      "8 : loss = 848.3815653931373\n",
      "9 : loss = 848.3815653931373\n",
      "10 : loss = 848.3815653931373\n",
      "11 : loss = 848.3815653931373\n",
      "12 : loss = 848.3815653931373\n",
      "13 : loss = 848.3815653931373\n",
      "14 : loss = 848.3815653931373\n",
      "15 : loss = 848.3815653931373\n",
      "16 : loss = 848.3815653931373\n",
      "17 : loss = 848.3815653931373\n",
      "18 : loss = 848.3815653931373\n",
      "19 : loss = 848.3815653931373\n",
      "20 : loss = 848.3815653931373\n",
      "21 : loss = 848.3815653931373\n",
      "22 : loss = 848.3815653931373\n",
      "23 : loss = 848.3815653931373\n",
      "24 : loss = 848.3815653931373\n",
      "25 : loss = 848.3815653931373\n",
      "26 : loss = 848.3815653931373\n",
      "27 : loss = 848.3815653931373\n",
      "28 : loss = 848.3815653931373\n",
      "29 : loss = 848.3815653931373\n",
      "0 : loss = 1014.7619945756613\n",
      "1 : loss = 1014.7619945756613\n",
      "2 : loss = 1014.7619945756613\n",
      "3 : loss = 1014.7619945756613\n",
      "4 : loss = 1014.7619945756613\n",
      "5 : loss = 1014.7619945756613\n",
      "6 : loss = 1014.7619945756613\n",
      "7 : loss = 1014.7619945756613\n",
      "8 : loss = 1014.7619945756613\n",
      "9 : loss = 1014.7619945756613\n",
      "10 : loss = 1014.7619945756613\n",
      "11 : loss = 1014.7619945756613\n",
      "12 : loss = 1014.7619945756613\n",
      "13 : loss = 1014.7619945756613\n",
      "14 : loss = 1014.7619945756613\n",
      "15 : loss = 1014.7619945756613\n",
      "16 : loss = 1014.7619945756613\n",
      "17 : loss = 1014.7619945756613\n",
      "18 : loss = 1014.7619945756613\n",
      "19 : loss = 1014.7619945756613\n",
      "20 : loss = 1014.7619945756613\n",
      "21 : loss = 1014.7619945756613\n",
      "22 : loss = 1014.7619945756613\n",
      "23 : loss = 1014.7619945756613\n",
      "24 : loss = 1014.7619945756613\n",
      "25 : loss = 1014.7619945756613\n",
      "26 : loss = 1014.7619945756613\n",
      "27 : loss = 1014.7619945756613\n",
      "28 : loss = 1014.7619945756613\n",
      "29 : loss = 1014.7619945756613\n",
      "0 : loss = 1113.0958797932944\n",
      "1 : loss = 1113.0958797932944\n",
      "2 : loss = 1113.0958797932944\n",
      "3 : loss = 1113.0958797932944\n",
      "4 : loss = 1113.0958797932944\n",
      "5 : loss = 1113.0958797932944\n",
      "6 : loss = 1113.0958797932944\n",
      "7 : loss = 1113.0958797932944\n",
      "8 : loss = 1113.0958797932944\n",
      "9 : loss = 1113.0958797932944\n",
      "10 : loss = 1113.0958797932944\n",
      "11 : loss = 1113.0958797932944\n",
      "12 : loss = 1113.0958797932944\n",
      "13 : loss = 1113.0958797932944\n",
      "14 : loss = 1113.0958797932944\n",
      "15 : loss = 1113.0958797932944\n",
      "16 : loss = 1113.0958797932944\n",
      "17 : loss = 1113.0958797932944\n",
      "18 : loss = 1113.0958797932944\n",
      "19 : loss = 1113.0958797932944\n",
      "20 : loss = 1113.0958797932944\n",
      "21 : loss = 1113.0958797932944\n",
      "22 : loss = 1113.0958797932944\n",
      "23 : loss = 1113.0958797932944\n",
      "24 : loss = 1113.0958797932944\n",
      "25 : loss = 1113.0958797932944\n",
      "26 : loss = 1113.0958797932944\n",
      "27 : loss = 1113.0958797932944\n",
      "28 : loss = 1113.0958797932944\n",
      "29 : loss = 1113.0958797932944\n",
      "0 : loss = 1286.1725026234037\n",
      "1 : loss = 1286.1725026234037\n",
      "2 : loss = 1286.1725026234037\n",
      "3 : loss = 1286.1725026234037\n",
      "4 : loss = 1286.1725026234037\n",
      "5 : loss = 1286.1725026234037\n",
      "6 : loss = 1286.1725026234037\n",
      "7 : loss = 1286.1725026234037\n",
      "8 : loss = 1286.1725026234037\n",
      "9 : loss = 1286.1725026234037\n",
      "10 : loss = 1286.1725026234037\n",
      "11 : loss = 1286.1725026234037\n",
      "12 : loss = 1286.1725026234037\n",
      "13 : loss = 1286.1725026234037\n",
      "14 : loss = 1286.1725026234037\n",
      "15 : loss = 1286.1725026234037\n",
      "16 : loss = 1286.1725026234037\n",
      "17 : loss = 1286.1725026234037\n",
      "18 : loss = 1286.1725026234037\n",
      "19 : loss = 1286.1725026234037\n",
      "20 : loss = 1286.1725026234037\n",
      "21 : loss = 1286.1725026234037\n",
      "22 : loss = 1286.1725026234037\n",
      "23 : loss = 1286.1725026234037\n",
      "24 : loss = 1286.1725026234037\n",
      "25 : loss = 1286.1725026234037\n",
      "26 : loss = 1286.1725026234037\n",
      "27 : loss = 1286.1725026234037\n",
      "28 : loss = 1286.1725026234037\n",
      "29 : loss = 1286.1725026234037\n",
      "0 : loss = 1363.504463541584\n",
      "1 : loss = 1363.504463541584\n",
      "2 : loss = 1363.504463541584\n",
      "3 : loss = 1363.504463541584\n",
      "4 : loss = 1363.504463541584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 : loss = 1363.504463541584\n",
      "6 : loss = 1363.504463541584\n",
      "7 : loss = 1363.504463541584\n",
      "8 : loss = 1363.504463541584\n",
      "9 : loss = 1363.504463541584\n",
      "10 : loss = 1363.504463541584\n",
      "11 : loss = 1363.504463541584\n",
      "12 : loss = 1363.504463541584\n",
      "13 : loss = 1363.504463541584\n",
      "14 : loss = 1363.504463541584\n",
      "15 : loss = 1363.504463541584\n",
      "16 : loss = 1363.504463541584\n",
      "17 : loss = 1363.504463541584\n",
      "18 : loss = 1363.504463541584\n",
      "19 : loss = 1363.504463541584\n",
      "20 : loss = 1363.504463541584\n",
      "21 : loss = 1363.504463541584\n",
      "22 : loss = 1363.504463541584\n",
      "23 : loss = 1363.504463541584\n",
      "24 : loss = 1363.504463541584\n",
      "25 : loss = 1363.504463541584\n",
      "26 : loss = 1363.504463541584\n",
      "27 : loss = 1363.504463541584\n",
      "28 : loss = 1363.504463541584\n",
      "29 : loss = 1363.504463541584\n",
      "0 : loss = 1505.5993444351432\n",
      "1 : loss = 1505.5993444351432\n",
      "2 : loss = 1505.5993444351432\n",
      "3 : loss = 1505.5993444351432\n",
      "4 : loss = 1505.5993444351432\n",
      "5 : loss = 1505.5993444351432\n",
      "6 : loss = 1505.5993444351432\n",
      "7 : loss = 1505.5993444351432\n",
      "8 : loss = 1505.5993444351432\n",
      "9 : loss = 1505.5993444351432\n",
      "10 : loss = 1505.5993444351432\n",
      "11 : loss = 1505.5993444351432\n",
      "12 : loss = 1505.5993444351432\n",
      "13 : loss = 1505.5993444351432\n",
      "14 : loss = 1505.5993444351432\n",
      "15 : loss = 1505.5993444351432\n",
      "16 : loss = 1505.5993444351432\n",
      "17 : loss = 1505.5993444351432\n",
      "18 : loss = 1505.5993444351432\n",
      "19 : loss = 1505.5993444351432\n",
      "20 : loss = 1505.5993444351432\n",
      "21 : loss = 1505.5993444351432\n",
      "22 : loss = 1505.5993444351432\n",
      "23 : loss = 1505.5993444351432\n",
      "24 : loss = 1505.5993444351432\n",
      "25 : loss = 1505.5993444351432\n",
      "26 : loss = 1505.5993444351432\n",
      "27 : loss = 1505.5993444351432\n",
      "28 : loss = 1505.5993444351432\n",
      "29 : loss = 1505.5993444351432\n",
      "0 : loss = 1591.4908869526655\n",
      "1 : loss = 1591.4908869526655\n",
      "2 : loss = 1591.4908869526655\n",
      "3 : loss = 1591.4908869526655\n",
      "4 : loss = 1591.4908869526655\n",
      "5 : loss = 1591.4908869526655\n",
      "6 : loss = 1591.4908869526655\n",
      "7 : loss = 1591.4908869526655\n",
      "8 : loss = 1591.4908869526655\n",
      "9 : loss = 1591.4908869526655\n",
      "10 : loss = 1591.4908869526655\n",
      "11 : loss = 1591.4908869526655\n",
      "12 : loss = 1591.4908869526655\n",
      "13 : loss = 1591.4908869526655\n",
      "14 : loss = 1591.4908869526655\n",
      "15 : loss = 1591.4908869526655\n",
      "16 : loss = 1591.4908869526655\n",
      "17 : loss = 1591.4908869526655\n",
      "18 : loss = 1591.4908869526655\n",
      "19 : loss = 1591.4908869526655\n",
      "20 : loss = 1591.4908869526655\n",
      "21 : loss = 1591.4908869526655\n",
      "22 : loss = 1591.4908869526655\n",
      "23 : loss = 1591.4908869526655\n",
      "24 : loss = 1591.4908869526655\n",
      "25 : loss = 1591.4908869526655\n",
      "26 : loss = 1591.4908869526655\n",
      "27 : loss = 1591.4908869526655\n",
      "28 : loss = 1591.4908869526655\n",
      "29 : loss = 1591.4908869526655\n",
      "0 : loss = 1751.949012531407\n",
      "1 : loss = 1751.949012531407\n",
      "2 : loss = 1751.949012531407\n",
      "3 : loss = 1751.949012531407\n",
      "4 : loss = 1751.949012531407\n",
      "5 : loss = 1751.949012531407\n",
      "6 : loss = 1751.949012531407\n",
      "7 : loss = 1751.949012531407\n",
      "8 : loss = 1751.949012531407\n",
      "9 : loss = 1751.949012531407\n",
      "10 : loss = 1751.949012531407\n",
      "11 : loss = 1751.949012531407\n",
      "12 : loss = 1751.949012531407\n",
      "13 : loss = 1751.949012531407\n",
      "14 : loss = 1751.949012531407\n",
      "15 : loss = 1751.949012531407\n",
      "16 : loss = 1751.949012531407\n",
      "17 : loss = 1751.949012531407\n",
      "18 : loss = 1751.949012531407\n",
      "19 : loss = 1751.949012531407\n",
      "20 : loss = 1751.949012531407\n",
      "21 : loss = 1751.949012531407\n",
      "22 : loss = 1751.949012531407\n",
      "23 : loss = 1751.949012531407\n",
      "24 : loss = 1751.949012531407\n",
      "25 : loss = 1751.949012531407\n",
      "26 : loss = 1751.949012531407\n",
      "27 : loss = 1751.949012531407\n",
      "28 : loss = 1751.949012531407\n",
      "29 : loss = 1751.949012531407\n",
      "0 : loss = 1850.0661040006346\n",
      "1 : loss = 1850.0661040006346\n",
      "2 : loss = 1850.0661040006346\n",
      "3 : loss = 1850.0661040006346\n",
      "4 : loss = 1850.0661040006346\n",
      "5 : loss = 1850.0661040006346\n",
      "6 : loss = 1850.0661040006346\n",
      "7 : loss = 1850.0661040006346\n",
      "8 : loss = 1850.0661040006346\n",
      "9 : loss = 1850.0661040006346\n",
      "10 : loss = 1850.0661040006346\n",
      "11 : loss = 1850.0661040006346\n",
      "12 : loss = 1850.0661040006346\n",
      "13 : loss = 1850.0661040006346\n",
      "14 : loss = 1850.0661040006346\n",
      "15 : loss = 1850.0661040006346\n",
      "16 : loss = 1850.0661040006346\n",
      "17 : loss = 1850.0661040006346\n",
      "18 : loss = 1850.0661040006346\n",
      "19 : loss = 1850.0661040006346\n",
      "20 : loss = 1850.0661040006346\n",
      "21 : loss = 1850.0661040006346\n",
      "22 : loss = 1850.0661040006346\n",
      "23 : loss = 1850.0661040006346\n",
      "24 : loss = 1850.0661040006346\n",
      "25 : loss = 1850.0661040006346\n",
      "26 : loss = 1850.0661040006346\n",
      "27 : loss = 1850.0661040006346\n",
      "28 : loss = 1850.0661040006346\n",
      "29 : loss = 1850.0661040006346\n",
      "0 : loss = 2000.381614261996\n",
      "1 : loss = 2000.381614261996\n",
      "2 : loss = 2000.381614261996\n",
      "3 : loss = 2000.381614261996\n",
      "4 : loss = 2000.381614261996\n",
      "5 : loss = 2000.381614261996\n",
      "6 : loss = 2000.381614261996\n",
      "7 : loss = 2000.381614261996\n",
      "8 : loss = 2000.381614261996\n",
      "9 : loss = 2000.381614261996\n",
      "10 : loss = 2000.381614261996\n",
      "11 : loss = 2000.381614261996\n",
      "12 : loss = 2000.381614261996\n",
      "13 : loss = 2000.381614261996\n",
      "14 : loss = 2000.381614261996\n",
      "15 : loss = 2000.381614261996\n",
      "16 : loss = 2000.381614261996\n",
      "17 : loss = 2000.381614261996\n",
      "18 : loss = 2000.381614261996\n",
      "19 : loss = 2000.381614261996\n",
      "20 : loss = 2000.381614261996\n",
      "21 : loss = 2000.381614261996\n",
      "22 : loss = 2000.381614261996\n",
      "23 : loss = 2000.381614261996\n",
      "24 : loss = 2000.381614261996\n",
      "25 : loss = 2000.381614261996\n",
      "26 : loss = 2000.381614261996\n",
      "27 : loss = 2000.381614261996\n",
      "28 : loss = 2000.381614261996\n",
      "29 : loss = 2000.381614261996\n",
      "0 : loss = 2078.2868960481514\n",
      "1 : loss = 2078.2868960481514\n",
      "2 : loss = 2078.2868960481514\n",
      "3 : loss = 2078.2868960481514\n",
      "4 : loss = 2078.2868960481514\n",
      "5 : loss = 2078.2868960481514\n",
      "6 : loss = 2078.2868960481514\n",
      "7 : loss = 2078.2868960481514\n",
      "8 : loss = 2078.2868960481514\n",
      "9 : loss = 2078.2868960481514\n",
      "10 : loss = 2078.2868960481514\n",
      "11 : loss = 2078.2868960481514\n",
      "12 : loss = 2078.2868960481514\n",
      "13 : loss = 2078.2868960481514\n",
      "14 : loss = 2078.2868960481514\n",
      "15 : loss = 2078.2868960481514\n",
      "16 : loss = 2078.2868960481514\n",
      "17 : loss = 2078.2868960481514\n",
      "18 : loss = 2078.2868960481514\n",
      "19 : loss = 2078.2868960481514\n",
      "20 : loss = 2078.2868960481514\n",
      "21 : loss = 2078.2868960481514\n",
      "22 : loss = 2078.2868960481514\n",
      "23 : loss = 2078.2868960481514\n",
      "24 : loss = 2078.2868960481514\n",
      "25 : loss = 2078.2868960481514\n",
      "26 : loss = 2078.2868960481514\n",
      "27 : loss = 2078.2868960481514\n",
      "28 : loss = 2078.2868960481514\n",
      "29 : loss = 2078.2868960481514\n",
      "0 : loss = 2212.9876454374544\n",
      "1 : loss = 2212.9876454374544\n",
      "2 : loss = 2212.9876454374544\n",
      "3 : loss = 2212.9876454374544\n",
      "4 : loss = 2212.9876454374544\n",
      "5 : loss = 2212.9876454374544\n",
      "6 : loss = 2212.9876454374544\n",
      "7 : loss = 2212.9876454374544\n",
      "8 : loss = 2212.9876454374544\n",
      "9 : loss = 2212.9876454374544\n",
      "10 : loss = 2212.9876454374544\n",
      "11 : loss = 2212.9876454374544\n",
      "12 : loss = 2212.9876454374544\n",
      "13 : loss = 2212.9876454374544\n",
      "14 : loss = 2212.9876454374544\n",
      "15 : loss = 2212.9876454374544\n",
      "16 : loss = 2212.9876454374544\n",
      "17 : loss = 2212.9876454374544\n",
      "18 : loss = 2212.9876454374544\n",
      "19 : loss = 2212.9876454374544\n",
      "20 : loss = 2212.9876454374544\n",
      "21 : loss = 2212.9876454374544\n",
      "22 : loss = 2212.9876454374544\n",
      "23 : loss = 2212.9876454374544\n",
      "24 : loss = 2212.9876454374544\n",
      "25 : loss = 2212.9876454374544\n",
      "26 : loss = 2212.9876454374544\n",
      "27 : loss = 2212.9876454374544\n",
      "28 : loss = 2212.9876454374544\n",
      "29 : loss = 2212.9876454374544\n",
      "0 : loss = 2316.613042916574\n",
      "1 : loss = 2316.613042916574\n",
      "2 : loss = 2316.613042916574\n",
      "3 : loss = 2316.613042916574\n",
      "4 : loss = 2316.613042916574\n",
      "5 : loss = 2316.613042916574\n",
      "6 : loss = 2316.613042916574\n",
      "7 : loss = 2316.613042916574\n",
      "8 : loss = 2316.613042916574\n",
      "9 : loss = 2316.613042916574\n",
      "10 : loss = 2316.613042916574\n",
      "11 : loss = 2316.613042916574\n",
      "12 : loss = 2316.613042916574\n",
      "13 : loss = 2316.613042916574\n",
      "14 : loss = 2316.613042916574\n",
      "15 : loss = 2316.613042916574\n",
      "16 : loss = 2316.613042916574\n",
      "17 : loss = 2316.613042916574\n",
      "18 : loss = 2316.613042916574\n",
      "19 : loss = 2316.613042916574\n",
      "20 : loss = 2316.613042916574\n",
      "21 : loss = 2316.613042916574\n",
      "22 : loss = 2316.613042916574\n",
      "23 : loss = 2316.613042916574\n",
      "24 : loss = 2316.613042916574\n",
      "25 : loss = 2316.613042916574\n",
      "26 : loss = 2316.613042916574\n",
      "27 : loss = 2316.613042916574\n",
      "28 : loss = 2316.613042916574\n",
      "29 : loss = 2316.613042916574\n",
      "0 : loss = 2476.625119688492\n",
      "1 : loss = 2476.625119688492\n",
      "2 : loss = 2476.625119688492\n",
      "3 : loss = 2476.625119688492\n",
      "4 : loss = 2476.625119688492\n",
      "5 : loss = 2476.625119688492\n",
      "6 : loss = 2476.625119688492\n",
      "7 : loss = 2476.625119688492\n",
      "8 : loss = 2476.625119688492\n",
      "9 : loss = 2476.625119688492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 : loss = 2476.625119688492\n",
      "11 : loss = 2476.625119688492\n",
      "12 : loss = 2476.625119688492\n",
      "13 : loss = 2476.625119688492\n",
      "14 : loss = 2476.625119688492\n",
      "15 : loss = 2476.625119688492\n",
      "16 : loss = 2476.625119688492\n",
      "17 : loss = 2476.625119688492\n",
      "18 : loss = 2476.625119688492\n",
      "19 : loss = 2476.625119688492\n",
      "20 : loss = 2476.625119688492\n",
      "21 : loss = 2476.625119688492\n",
      "22 : loss = 2476.625119688492\n",
      "23 : loss = 2476.625119688492\n",
      "24 : loss = 2476.625119688492\n",
      "25 : loss = 2476.625119688492\n",
      "26 : loss = 2476.625119688492\n",
      "27 : loss = 2476.625119688492\n",
      "28 : loss = 2476.625119688492\n",
      "29 : loss = 2476.625119688492\n",
      "0 : loss = 2567.2991932408495\n",
      "1 : loss = 2567.2991932408495\n",
      "2 : loss = 2567.2991932408495\n",
      "3 : loss = 2567.2991932408495\n",
      "4 : loss = 2567.2991932408495\n",
      "5 : loss = 2567.2991932408495\n",
      "6 : loss = 2567.2991932408495\n",
      "7 : loss = 2567.2991932408495\n",
      "8 : loss = 2567.2991932408495\n",
      "9 : loss = 2567.2991932408495\n",
      "10 : loss = 2567.2991932408495\n",
      "11 : loss = 2567.2991932408495\n",
      "12 : loss = 2567.2991932408495\n",
      "13 : loss = 2567.2991932408495\n",
      "14 : loss = 2567.2991932408495\n",
      "15 : loss = 2567.2991932408495\n",
      "16 : loss = 2567.2991932408495\n",
      "17 : loss = 2567.2991932408495\n",
      "18 : loss = 2567.2991932408495\n",
      "19 : loss = 2567.2991932408495\n",
      "20 : loss = 2567.2991932408495\n",
      "21 : loss = 2567.2991932408495\n",
      "22 : loss = 2567.2991932408495\n",
      "23 : loss = 2567.2991932408495\n",
      "24 : loss = 2567.2991932408495\n",
      "25 : loss = 2567.2991932408495\n",
      "26 : loss = 2567.2991932408495\n",
      "27 : loss = 2567.2991932408495\n",
      "28 : loss = 2567.2991932408495\n",
      "29 : loss = 2567.2991932408495\n",
      "k:  0\n",
      "weight[0] shape:  torch.Size([50, 40000])\n",
      "bias[0] shape:  torch.Size([50, 1])\n",
      "Relu Params[0]:  0.0060149751099436355\n",
      "BN gamma[0]:  1.0143986959665934\n",
      "BN beta[0]:  0.00039869627951913557\n",
      "weight[1] shape:  torch.Size([50, 50])\n",
      "bias[1] shape:  torch.Size([50, 1])\n",
      "Relu Params[1]:  0.01\n",
      "BN gamma[1]:  0.9991703508639939\n",
      "BN beta[1]:  0.00039869627951913557\n",
      "weight[2] shape:  torch.Size([50, 50])\n",
      "bias[2] shape:  torch.Size([50, 1])\n",
      "Relu Params[2]:  0.01\n",
      "BN gamma[2]:  1.00072838332199\n",
      "BN beta[2]:  0.0003996150144270226\n",
      "weight[3] shape:  torch.Size([40000, 50])\n",
      "bias[3] shape:  torch.Size([40000, 1])\n",
      "Relu Params[3]:  0.013613461265533214\n",
      "BN gamma[3]:  1\n",
      "BN beta[3]:  0\n",
      "0 : loss = 65.8788267650409\n",
      "1 : loss = 65.8788267650409\n",
      "2 : loss = 65.8788267650409\n",
      "3 : loss = 65.8788267650409\n",
      "4 : loss = 65.8788267650409\n",
      "5 : loss = 65.8788267650409\n",
      "6 : loss = 65.8788267650409\n",
      "7 : loss = 65.8788267650409\n",
      "8 : loss = 65.8788267650409\n",
      "9 : loss = 65.8788267650409\n",
      "10 : loss = 65.8788267650409\n",
      "11 : loss = 65.8788267650409\n",
      "12 : loss = 65.8788267650409\n",
      "13 : loss = 65.8788267650409\n",
      "14 : loss = 65.8788267650409\n",
      "15 : loss = 65.8788267650409\n",
      "16 : loss = 65.8788267650409\n",
      "17 : loss = 65.8788267650409\n",
      "18 : loss = 65.8788267650409\n",
      "19 : loss = 65.8788267650409\n",
      "20 : loss = 65.8788267650409\n",
      "21 : loss = 65.8788267650409\n",
      "22 : loss = 65.8788267650409\n",
      "23 : loss = 65.8788267650409\n",
      "24 : loss = 65.8788267650409\n",
      "25 : loss = 65.8788267650409\n",
      "26 : loss = 65.8788267650409\n",
      "27 : loss = 65.8788267650409\n",
      "28 : loss = 65.8788267650409\n",
      "29 : loss = 65.8788267650409\n",
      "0 : loss = 275.37036171610055\n",
      "1 : loss = 275.37036171610055\n",
      "2 : loss = 275.37036171610055\n",
      "3 : loss = 275.37036171610055\n",
      "4 : loss = 275.37036171610055\n",
      "5 : loss = 275.37036171610055\n",
      "6 : loss = 275.37036171610055\n",
      "7 : loss = 275.37036171610055\n",
      "8 : loss = 275.37036171610055\n",
      "9 : loss = 275.37036171610055\n",
      "10 : loss = 275.37036171610055\n",
      "11 : loss = 275.37036171610055\n",
      "12 : loss = 275.37036171610055\n",
      "13 : loss = 275.37036171610055\n",
      "14 : loss = 275.37036171610055\n",
      "15 : loss = 275.37036171610055\n",
      "16 : loss = 275.37036171610055\n",
      "17 : loss = 275.37036171610055\n",
      "18 : loss = 275.37036171610055\n",
      "19 : loss = 275.37036171610055\n",
      "20 : loss = 275.37036171610055\n",
      "21 : loss = 275.37036171610055\n",
      "22 : loss = 275.37036171610055\n",
      "23 : loss = 275.37036171610055\n",
      "24 : loss = 275.37036171610055\n",
      "25 : loss = 275.37036171610055\n",
      "26 : loss = 275.37036171610055\n",
      "27 : loss = 275.37036171610055\n",
      "28 : loss = 275.37036171610055\n",
      "29 : loss = 275.37036171610055\n",
      "0 : loss = 520.8323274616995\n",
      "1 : loss = 520.8323274616995\n",
      "2 : loss = 520.8323274616995\n",
      "3 : loss = 520.8323274616995\n",
      "4 : loss = 520.8323274616995\n",
      "5 : loss = 520.8323274616995\n",
      "6 : loss = 520.8323274616995\n",
      "7 : loss = 520.8323274616995\n",
      "8 : loss = 520.8323274616995\n",
      "9 : loss = 520.8323274616995\n",
      "10 : loss = 520.8323274616995\n",
      "11 : loss = 520.8323274616995\n",
      "12 : loss = 520.8323274616995\n",
      "13 : loss = 520.8323274616995\n",
      "14 : loss = 520.8323274616995\n",
      "15 : loss = 520.8323274616995\n",
      "16 : loss = 520.8323274616995\n",
      "17 : loss = 520.8323274616995\n",
      "18 : loss = 520.8323274616995\n",
      "19 : loss = 520.8323274616995\n",
      "20 : loss = 520.8323274616995\n",
      "21 : loss = 520.8323274616995\n",
      "22 : loss = 520.8323274616995\n",
      "23 : loss = 520.8323274616995\n",
      "24 : loss = 520.8323274616995\n",
      "25 : loss = 520.8323274616995\n",
      "26 : loss = 520.8323274616995\n",
      "27 : loss = 520.8323274616995\n",
      "28 : loss = 520.8323274616995\n",
      "29 : loss = 520.8323274616995\n",
      "0 : loss = 608.4136001772553\n",
      "1 : loss = 608.4136001772553\n",
      "2 : loss = 608.4136001772553\n",
      "3 : loss = 608.4136001772553\n",
      "4 : loss = 608.4136001772553\n",
      "5 : loss = 608.4136001772553\n",
      "6 : loss = 608.4136001772553\n",
      "7 : loss = 608.4136001772553\n",
      "8 : loss = 608.4136001772553\n",
      "9 : loss = 608.4136001772553\n",
      "10 : loss = 608.4136001772553\n",
      "11 : loss = 608.4136001772553\n",
      "12 : loss = 608.4136001772553\n",
      "13 : loss = 608.4136001772553\n",
      "14 : loss = 608.4136001772553\n",
      "15 : loss = 608.4136001772553\n",
      "16 : loss = 608.4136001772553\n",
      "17 : loss = 608.4136001772553\n",
      "18 : loss = 608.4136001772553\n",
      "19 : loss = 608.4136001772553\n",
      "20 : loss = 608.4136001772553\n",
      "21 : loss = 608.4136001772553\n",
      "22 : loss = 608.4136001772553\n",
      "23 : loss = 608.4136001772553\n",
      "24 : loss = 608.4136001772553\n",
      "25 : loss = 608.4136001772553\n",
      "26 : loss = 608.4136001772553\n",
      "27 : loss = 608.4136001772553\n",
      "28 : loss = 608.4136001772553\n",
      "29 : loss = 608.4136001772553\n",
      "0 : loss = 771.1963785192931\n",
      "1 : loss = 771.1963785192931\n",
      "2 : loss = 771.1963785192931\n",
      "3 : loss = 771.1963785192931\n",
      "4 : loss = 771.1963785192931\n",
      "5 : loss = 771.1963785192931\n",
      "6 : loss = 771.1963785192931\n",
      "7 : loss = 771.1963785192931\n",
      "8 : loss = 771.1963785192931\n",
      "9 : loss = 771.1963785192931\n",
      "10 : loss = 771.1963785192931\n",
      "11 : loss = 771.1963785192931\n",
      "12 : loss = 771.1963785192931\n",
      "13 : loss = 771.1963785192931\n",
      "14 : loss = 771.1963785192931\n",
      "15 : loss = 771.1963785192931\n",
      "16 : loss = 771.1963785192931\n",
      "17 : loss = 771.1963785192931\n",
      "18 : loss = 771.1963785192931\n",
      "19 : loss = 771.1963785192931\n",
      "20 : loss = 771.1963785192931\n",
      "21 : loss = 771.1963785192931\n",
      "22 : loss = 771.1963785192931\n",
      "23 : loss = 771.1963785192931\n",
      "24 : loss = 771.1963785192931\n",
      "25 : loss = 771.1963785192931\n",
      "26 : loss = 771.1963785192931\n",
      "27 : loss = 771.1963785192931\n",
      "28 : loss = 771.1963785192931\n",
      "29 : loss = 771.1963785192931\n",
      "0 : loss = 848.3815653931373\n",
      "1 : loss = 848.3815653931373\n",
      "2 : loss = 848.3815653931373\n",
      "3 : loss = 848.3815653931373\n",
      "4 : loss = 848.3815653931373\n",
      "5 : loss = 848.3815653931373\n",
      "6 : loss = 848.3815653931373\n",
      "7 : loss = 848.3815653931373\n",
      "8 : loss = 848.3815653931373\n",
      "9 : loss = 848.3815653931373\n",
      "10 : loss = 848.3815653931373\n",
      "11 : loss = 848.3815653931373\n",
      "12 : loss = 848.3815653931373\n",
      "13 : loss = 848.3815653931373\n",
      "14 : loss = 848.3815653931373\n",
      "15 : loss = 848.3815653931373\n",
      "16 : loss = 848.3815653931373\n",
      "17 : loss = 848.3815653931373\n",
      "18 : loss = 848.3815653931373\n",
      "19 : loss = 848.3815653931373\n",
      "20 : loss = 848.3815653931373\n",
      "21 : loss = 848.3815653931373\n",
      "22 : loss = 848.3815653931373\n",
      "23 : loss = 848.3815653931373\n",
      "24 : loss = 848.3815653931373\n",
      "25 : loss = 848.3815653931373\n",
      "26 : loss = 848.3815653931373\n",
      "27 : loss = 848.3815653931373\n",
      "28 : loss = 848.3815653931373\n",
      "29 : loss = 848.3815653931373\n",
      "0 : loss = 1014.7619945756613\n",
      "1 : loss = 1014.7619945756613\n",
      "2 : loss = 1014.7619945756613\n",
      "3 : loss = 1014.7619945756613\n",
      "4 : loss = 1014.7619945756613\n",
      "5 : loss = 1014.7619945756613\n",
      "6 : loss = 1014.7619945756613\n",
      "7 : loss = 1014.7619945756613\n",
      "8 : loss = 1014.7619945756613\n",
      "9 : loss = 1014.7619945756613\n",
      "10 : loss = 1014.7619945756613\n",
      "11 : loss = 1014.7619945756613\n",
      "12 : loss = 1014.7619945756613\n",
      "13 : loss = 1014.7619945756613\n",
      "14 : loss = 1014.7619945756613\n",
      "15 : loss = 1014.7619945756613\n",
      "16 : loss = 1014.7619945756613\n",
      "17 : loss = 1014.7619945756613\n",
      "18 : loss = 1014.7619945756613\n",
      "19 : loss = 1014.7619945756613\n",
      "20 : loss = 1014.7619945756613\n",
      "21 : loss = 1014.7619945756613\n",
      "22 : loss = 1014.7619945756613\n",
      "23 : loss = 1014.7619945756613\n",
      "24 : loss = 1014.7619945756613\n",
      "25 : loss = 1014.7619945756613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 : loss = 1014.7619945756613\n",
      "27 : loss = 1014.7619945756613\n",
      "28 : loss = 1014.7619945756613\n",
      "29 : loss = 1014.7619945756613\n",
      "0 : loss = 1113.0958797932944\n",
      "1 : loss = 1113.0958797932944\n",
      "2 : loss = 1113.0958797932944\n",
      "3 : loss = 1113.0958797932944\n",
      "4 : loss = 1113.0958797932944\n",
      "5 : loss = 1113.0958797932944\n",
      "6 : loss = 1113.0958797932944\n",
      "7 : loss = 1113.0958797932944\n",
      "8 : loss = 1113.0958797932944\n",
      "9 : loss = 1113.0958797932944\n",
      "10 : loss = 1113.0958797932944\n",
      "11 : loss = 1113.0958797932944\n",
      "12 : loss = 1113.0958797932944\n",
      "13 : loss = 1113.0958797932944\n",
      "14 : loss = 1113.0958797932944\n",
      "15 : loss = 1113.0958797932944\n",
      "16 : loss = 1113.0958797932944\n",
      "17 : loss = 1113.0958797932944\n",
      "18 : loss = 1113.0958797932944\n",
      "19 : loss = 1113.0958797932944\n",
      "20 : loss = 1113.0958797932944\n",
      "21 : loss = 1113.0958797932944\n",
      "22 : loss = 1113.0958797932944\n",
      "23 : loss = 1113.0958797932944\n",
      "24 : loss = 1113.0958797932944\n",
      "25 : loss = 1113.0958797932944\n",
      "26 : loss = 1113.0958797932944\n",
      "27 : loss = 1113.0958797932944\n",
      "28 : loss = 1113.0958797932944\n",
      "29 : loss = 1113.0958797932944\n",
      "0 : loss = 1286.1725026234037\n",
      "1 : loss = 1286.1725026234037\n",
      "2 : loss = 1286.1725026234037\n",
      "3 : loss = 1286.1725026234037\n",
      "4 : loss = 1286.1725026234037\n",
      "5 : loss = 1286.1725026234037\n",
      "6 : loss = 1286.1725026234037\n",
      "7 : loss = 1286.1725026234037\n",
      "8 : loss = 1286.1725026234037\n",
      "9 : loss = 1286.1725026234037\n",
      "10 : loss = 1286.1725026234037\n",
      "11 : loss = 1286.1725026234037\n",
      "12 : loss = 1286.1725026234037\n",
      "13 : loss = 1286.1725026234037\n",
      "14 : loss = 1286.1725026234037\n",
      "15 : loss = 1286.1725026234037\n",
      "16 : loss = 1286.1725026234037\n",
      "17 : loss = 1286.1725026234037\n",
      "18 : loss = 1286.1725026234037\n",
      "19 : loss = 1286.1725026234037\n",
      "20 : loss = 1286.1725026234037\n",
      "21 : loss = 1286.1725026234037\n",
      "22 : loss = 1286.1725026234037\n",
      "23 : loss = 1286.1725026234037\n",
      "24 : loss = 1286.1725026234037\n",
      "25 : loss = 1286.1725026234037\n",
      "26 : loss = 1286.1725026234037\n",
      "27 : loss = 1286.1725026234037\n",
      "28 : loss = 1286.1725026234037\n",
      "29 : loss = 1286.1725026234037\n",
      "0 : loss = 1363.504463541584\n",
      "1 : loss = 1363.504463541584\n",
      "2 : loss = 1363.504463541584\n",
      "3 : loss = 1363.504463541584\n",
      "4 : loss = 1363.504463541584\n",
      "5 : loss = 1363.504463541584\n",
      "6 : loss = 1363.504463541584\n",
      "7 : loss = 1363.504463541584\n",
      "8 : loss = 1363.504463541584\n",
      "9 : loss = 1363.504463541584\n",
      "10 : loss = 1363.504463541584\n",
      "11 : loss = 1363.504463541584\n",
      "12 : loss = 1363.504463541584\n",
      "13 : loss = 1363.504463541584\n",
      "14 : loss = 1363.504463541584\n",
      "15 : loss = 1363.504463541584\n",
      "16 : loss = 1363.504463541584\n",
      "17 : loss = 1363.504463541584\n",
      "18 : loss = 1363.504463541584\n",
      "19 : loss = 1363.504463541584\n",
      "20 : loss = 1363.504463541584\n",
      "21 : loss = 1363.504463541584\n",
      "22 : loss = 1363.504463541584\n",
      "23 : loss = 1363.504463541584\n",
      "24 : loss = 1363.504463541584\n",
      "25 : loss = 1363.504463541584\n",
      "26 : loss = 1363.504463541584\n",
      "27 : loss = 1363.504463541584\n",
      "28 : loss = 1363.504463541584\n",
      "29 : loss = 1363.504463541584\n",
      "0 : loss = 1505.5993444351432\n",
      "1 : loss = 1505.5993444351432\n",
      "2 : loss = 1505.5993444351432\n",
      "3 : loss = 1505.5993444351432\n",
      "4 : loss = 1505.5993444351432\n",
      "5 : loss = 1505.5993444351432\n",
      "6 : loss = 1505.5993444351432\n",
      "7 : loss = 1505.5993444351432\n",
      "8 : loss = 1505.5993444351432\n",
      "9 : loss = 1505.5993444351432\n",
      "10 : loss = 1505.5993444351432\n",
      "11 : loss = 1505.5993444351432\n",
      "12 : loss = 1505.5993444351432\n",
      "13 : loss = 1505.5993444351432\n",
      "14 : loss = 1505.5993444351432\n",
      "15 : loss = 1505.5993444351432\n",
      "16 : loss = 1505.5993444351432\n",
      "17 : loss = 1505.5993444351432\n",
      "18 : loss = 1505.5993444351432\n",
      "19 : loss = 1505.5993444351432\n",
      "20 : loss = 1505.5993444351432\n",
      "21 : loss = 1505.5993444351432\n",
      "22 : loss = 1505.5993444351432\n",
      "23 : loss = 1505.5993444351432\n",
      "24 : loss = 1505.5993444351432\n",
      "25 : loss = 1505.5993444351432\n",
      "26 : loss = 1505.5993444351432\n",
      "27 : loss = 1505.5993444351432\n",
      "28 : loss = 1505.5993444351432\n",
      "29 : loss = 1505.5993444351432\n",
      "0 : loss = 1591.4908869526655\n",
      "1 : loss = 1591.4908869526655\n",
      "2 : loss = 1591.4908869526655\n",
      "3 : loss = 1591.4908869526655\n",
      "4 : loss = 1591.4908869526655\n",
      "5 : loss = 1591.4908869526655\n",
      "6 : loss = 1591.4908869526655\n",
      "7 : loss = 1591.4908869526655\n",
      "8 : loss = 1591.4908869526655\n",
      "9 : loss = 1591.4908869526655\n",
      "10 : loss = 1591.4908869526655\n",
      "11 : loss = 1591.4908869526655\n",
      "12 : loss = 1591.4908869526655\n",
      "13 : loss = 1591.4908869526655\n",
      "14 : loss = 1591.4908869526655\n",
      "15 : loss = 1591.4908869526655\n",
      "16 : loss = 1591.4908869526655\n",
      "17 : loss = 1591.4908869526655\n",
      "18 : loss = 1591.4908869526655\n",
      "19 : loss = 1591.4908869526655\n",
      "20 : loss = 1591.4908869526655\n",
      "21 : loss = 1591.4908869526655\n",
      "22 : loss = 1591.4908869526655\n",
      "23 : loss = 1591.4908869526655\n",
      "24 : loss = 1591.4908869526655\n",
      "25 : loss = 1591.4908869526655\n",
      "26 : loss = 1591.4908869526655\n",
      "27 : loss = 1591.4908869526655\n",
      "28 : loss = 1591.4908869526655\n",
      "29 : loss = 1591.4908869526655\n",
      "0 : loss = 1751.949012531407\n",
      "1 : loss = 1751.949012531407\n",
      "2 : loss = 1751.949012531407\n",
      "3 : loss = 1751.949012531407\n",
      "4 : loss = 1751.949012531407\n",
      "5 : loss = 1751.949012531407\n",
      "6 : loss = 1751.949012531407\n",
      "7 : loss = 1751.949012531407\n",
      "8 : loss = 1751.949012531407\n",
      "9 : loss = 1751.949012531407\n",
      "10 : loss = 1751.949012531407\n",
      "11 : loss = 1751.949012531407\n",
      "12 : loss = 1751.949012531407\n",
      "13 : loss = 1751.949012531407\n",
      "14 : loss = 1751.949012531407\n",
      "15 : loss = 1751.949012531407\n",
      "16 : loss = 1751.949012531407\n",
      "17 : loss = 1751.949012531407\n",
      "18 : loss = 1751.949012531407\n",
      "19 : loss = 1751.949012531407\n",
      "20 : loss = 1751.949012531407\n",
      "21 : loss = 1751.949012531407\n",
      "22 : loss = 1751.949012531407\n",
      "23 : loss = 1751.949012531407\n",
      "24 : loss = 1751.949012531407\n",
      "25 : loss = 1751.949012531407\n",
      "26 : loss = 1751.949012531407\n",
      "27 : loss = 1751.949012531407\n",
      "28 : loss = 1751.949012531407\n",
      "29 : loss = 1751.949012531407\n",
      "0 : loss = 1850.0661040006346\n",
      "1 : loss = 1850.0661040006346\n",
      "2 : loss = 1850.0661040006346\n",
      "3 : loss = 1850.0661040006346\n",
      "4 : loss = 1850.0661040006346\n",
      "5 : loss = 1850.0661040006346\n",
      "6 : loss = 1850.0661040006346\n",
      "7 : loss = 1850.0661040006346\n",
      "8 : loss = 1850.0661040006346\n",
      "9 : loss = 1850.0661040006346\n",
      "10 : loss = 1850.0661040006346\n",
      "11 : loss = 1850.0661040006346\n",
      "12 : loss = 1850.0661040006346\n",
      "13 : loss = 1850.0661040006346\n",
      "14 : loss = 1850.0661040006346\n",
      "15 : loss = 1850.0661040006346\n",
      "16 : loss = 1850.0661040006346\n",
      "17 : loss = 1850.0661040006346\n",
      "18 : loss = 1850.0661040006346\n",
      "19 : loss = 1850.0661040006346\n",
      "20 : loss = 1850.0661040006346\n",
      "21 : loss = 1850.0661040006346\n",
      "22 : loss = 1850.0661040006346\n",
      "23 : loss = 1850.0661040006346\n",
      "24 : loss = 1850.0661040006346\n",
      "25 : loss = 1850.0661040006346\n",
      "26 : loss = 1850.0661040006346\n",
      "27 : loss = 1850.0661040006346\n",
      "28 : loss = 1850.0661040006346\n",
      "29 : loss = 1850.0661040006346\n",
      "0 : loss = 2000.381614261996\n",
      "1 : loss = 2000.381614261996\n",
      "2 : loss = 2000.381614261996\n",
      "3 : loss = 2000.381614261996\n",
      "4 : loss = 2000.381614261996\n",
      "5 : loss = 2000.381614261996\n",
      "6 : loss = 2000.381614261996\n",
      "7 : loss = 2000.381614261996\n",
      "8 : loss = 2000.381614261996\n",
      "9 : loss = 2000.381614261996\n",
      "10 : loss = 2000.381614261996\n",
      "11 : loss = 2000.381614261996\n",
      "12 : loss = 2000.381614261996\n",
      "13 : loss = 2000.381614261996\n",
      "14 : loss = 2000.381614261996\n",
      "15 : loss = 2000.381614261996\n",
      "16 : loss = 2000.381614261996\n",
      "17 : loss = 2000.381614261996\n",
      "18 : loss = 2000.381614261996\n",
      "19 : loss = 2000.381614261996\n",
      "20 : loss = 2000.381614261996\n",
      "21 : loss = 2000.381614261996\n",
      "22 : loss = 2000.381614261996\n",
      "23 : loss = 2000.381614261996\n",
      "24 : loss = 2000.381614261996\n",
      "25 : loss = 2000.381614261996\n",
      "26 : loss = 2000.381614261996\n",
      "27 : loss = 2000.381614261996\n",
      "28 : loss = 2000.381614261996\n",
      "29 : loss = 2000.381614261996\n",
      "0 : loss = 2078.2868960481514\n",
      "1 : loss = 2078.2868960481514\n",
      "2 : loss = 2078.2868960481514\n",
      "3 : loss = 2078.2868960481514\n",
      "4 : loss = 2078.2868960481514\n",
      "5 : loss = 2078.2868960481514\n",
      "6 : loss = 2078.2868960481514\n",
      "7 : loss = 2078.2868960481514\n",
      "8 : loss = 2078.2868960481514\n",
      "9 : loss = 2078.2868960481514\n",
      "10 : loss = 2078.2868960481514\n",
      "11 : loss = 2078.2868960481514\n",
      "12 : loss = 2078.2868960481514\n",
      "13 : loss = 2078.2868960481514\n",
      "14 : loss = 2078.2868960481514\n",
      "15 : loss = 2078.2868960481514\n",
      "16 : loss = 2078.2868960481514\n",
      "17 : loss = 2078.2868960481514\n",
      "18 : loss = 2078.2868960481514\n",
      "19 : loss = 2078.2868960481514\n",
      "20 : loss = 2078.2868960481514\n",
      "21 : loss = 2078.2868960481514\n",
      "22 : loss = 2078.2868960481514\n",
      "23 : loss = 2078.2868960481514\n",
      "24 : loss = 2078.2868960481514\n",
      "25 : loss = 2078.2868960481514\n",
      "26 : loss = 2078.2868960481514\n",
      "27 : loss = 2078.2868960481514\n",
      "28 : loss = 2078.2868960481514\n",
      "29 : loss = 2078.2868960481514\n",
      "0 : loss = 2212.9876454374544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : loss = 2212.9876454374544\n",
      "2 : loss = 2212.9876454374544\n",
      "3 : loss = 2212.9876454374544\n",
      "4 : loss = 2212.9876454374544\n",
      "5 : loss = 2212.9876454374544\n",
      "6 : loss = 2212.9876454374544\n",
      "7 : loss = 2212.9876454374544\n",
      "8 : loss = 2212.9876454374544\n",
      "9 : loss = 2212.9876454374544\n",
      "10 : loss = 2212.9876454374544\n",
      "11 : loss = 2212.9876454374544\n",
      "12 : loss = 2212.9876454374544\n",
      "13 : loss = 2212.9876454374544\n",
      "14 : loss = 2212.9876454374544\n",
      "15 : loss = 2212.9876454374544\n",
      "16 : loss = 2212.9876454374544\n",
      "17 : loss = 2212.9876454374544\n",
      "18 : loss = 2212.9876454374544\n",
      "19 : loss = 2212.9876454374544\n",
      "20 : loss = 2212.9876454374544\n",
      "21 : loss = 2212.9876454374544\n",
      "22 : loss = 2212.9876454374544\n",
      "23 : loss = 2212.9876454374544\n",
      "24 : loss = 2212.9876454374544\n",
      "25 : loss = 2212.9876454374544\n",
      "26 : loss = 2212.9876454374544\n",
      "27 : loss = 2212.9876454374544\n",
      "28 : loss = 2212.9876454374544\n",
      "29 : loss = 2212.9876454374544\n",
      "0 : loss = 2316.613042916574\n",
      "1 : loss = 2316.613042916574\n",
      "2 : loss = 2316.613042916574\n",
      "3 : loss = 2316.613042916574\n",
      "4 : loss = 2316.613042916574\n",
      "5 : loss = 2316.613042916574\n",
      "6 : loss = 2316.613042916574\n",
      "7 : loss = 2316.613042916574\n",
      "8 : loss = 2316.613042916574\n",
      "9 : loss = 2316.613042916574\n",
      "10 : loss = 2316.613042916574\n",
      "11 : loss = 2316.613042916574\n",
      "12 : loss = 2316.613042916574\n",
      "13 : loss = 2316.613042916574\n",
      "14 : loss = 2316.613042916574\n",
      "15 : loss = 2316.613042916574\n",
      "16 : loss = 2316.613042916574\n",
      "17 : loss = 2316.613042916574\n",
      "18 : loss = 2316.613042916574\n",
      "19 : loss = 2316.613042916574\n",
      "20 : loss = 2316.613042916574\n",
      "21 : loss = 2316.613042916574\n",
      "22 : loss = 2316.613042916574\n",
      "23 : loss = 2316.613042916574\n",
      "24 : loss = 2316.613042916574\n",
      "25 : loss = 2316.613042916574\n",
      "26 : loss = 2316.613042916574\n",
      "27 : loss = 2316.613042916574\n",
      "28 : loss = 2316.613042916574\n",
      "29 : loss = 2316.613042916574\n",
      "0 : loss = 2476.625119688492\n",
      "1 : loss = 2476.625119688492\n",
      "2 : loss = 2476.625119688492\n",
      "3 : loss = 2476.625119688492\n",
      "4 : loss = 2476.625119688492\n",
      "5 : loss = 2476.625119688492\n",
      "6 : loss = 2476.625119688492\n",
      "7 : loss = 2476.625119688492\n",
      "8 : loss = 2476.625119688492\n",
      "9 : loss = 2476.625119688492\n",
      "10 : loss = 2476.625119688492\n",
      "11 : loss = 2476.625119688492\n",
      "12 : loss = 2476.625119688492\n",
      "13 : loss = 2476.625119688492\n",
      "14 : loss = 2476.625119688492\n",
      "15 : loss = 2476.625119688492\n",
      "16 : loss = 2476.625119688492\n",
      "17 : loss = 2476.625119688492\n",
      "18 : loss = 2476.625119688492\n",
      "19 : loss = 2476.625119688492\n",
      "20 : loss = 2476.625119688492\n",
      "21 : loss = 2476.625119688492\n",
      "22 : loss = 2476.625119688492\n",
      "23 : loss = 2476.625119688492\n",
      "24 : loss = 2476.625119688492\n",
      "25 : loss = 2476.625119688492\n",
      "26 : loss = 2476.625119688492\n",
      "27 : loss = 2476.625119688492\n",
      "28 : loss = 2476.625119688492\n",
      "29 : loss = 2476.625119688492\n",
      "0 : loss = 2567.2991932408495\n",
      "1 : loss = 2567.2991932408495\n",
      "2 : loss = 2567.2991932408495\n",
      "3 : loss = 2567.2991932408495\n",
      "4 : loss = 2567.2991932408495\n",
      "5 : loss = 2567.2991932408495\n",
      "6 : loss = 2567.2991932408495\n",
      "7 : loss = 2567.2991932408495\n",
      "8 : loss = 2567.2991932408495\n",
      "9 : loss = 2567.2991932408495\n",
      "10 : loss = 2567.2991932408495\n",
      "11 : loss = 2567.2991932408495\n",
      "12 : loss = 2567.2991932408495\n",
      "13 : loss = 2567.2991932408495\n",
      "14 : loss = 2567.2991932408495\n",
      "15 : loss = 2567.2991932408495\n",
      "16 : loss = 2567.2991932408495\n",
      "17 : loss = 2567.2991932408495\n",
      "18 : loss = 2567.2991932408495\n",
      "19 : loss = 2567.2991932408495\n",
      "20 : loss = 2567.2991932408495\n",
      "21 : loss = 2567.2991932408495\n",
      "22 : loss = 2567.2991932408495\n",
      "23 : loss = 2567.2991932408495\n",
      "24 : loss = 2567.2991932408495\n",
      "25 : loss = 2567.2991932408495\n",
      "26 : loss = 2567.2991932408495\n",
      "27 : loss = 2567.2991932408495\n",
      "28 : loss = 2567.2991932408495\n",
      "29 : loss = 2567.2991932408495\n",
      "k:  1\n",
      "weight[0] shape:  torch.Size([50, 40000])\n",
      "bias[0] shape:  torch.Size([50, 1])\n",
      "Relu Params[0]:  0.0060149751099436355\n",
      "BN gamma[0]:  1.0143986959665934\n",
      "BN beta[0]:  0.00039869627951913557\n",
      "weight[1] shape:  torch.Size([50, 50])\n",
      "bias[1] shape:  torch.Size([50, 1])\n",
      "Relu Params[1]:  0.01\n",
      "BN gamma[1]:  0.9991703508639939\n",
      "BN beta[1]:  0.00039869627951913557\n",
      "weight[2] shape:  torch.Size([50, 50])\n",
      "bias[2] shape:  torch.Size([50, 1])\n",
      "Relu Params[2]:  0.01\n",
      "BN gamma[2]:  1.00072838332199\n",
      "BN beta[2]:  0.0003996150144270226\n",
      "weight[3] shape:  torch.Size([40000, 50])\n",
      "bias[3] shape:  torch.Size([40000, 1])\n",
      "Relu Params[3]:  0.013613461265533214\n",
      "BN gamma[3]:  1\n",
      "BN beta[3]:  0\n",
      "0 : loss = 65.8788267650409\n",
      "1 : loss = 65.8788267650409\n",
      "2 : loss = 65.8788267650409\n",
      "3 : loss = 65.8788267650409\n",
      "4 : loss = 65.8788267650409\n",
      "5 : loss = 65.8788267650409\n",
      "6 : loss = 65.8788267650409\n",
      "7 : loss = 65.8788267650409\n",
      "8 : loss = 65.8788267650409\n",
      "9 : loss = 65.8788267650409\n",
      "10 : loss = 65.8788267650409\n",
      "11 : loss = 65.8788267650409\n",
      "12 : loss = 65.8788267650409\n",
      "13 : loss = 65.8788267650409\n",
      "14 : loss = 65.8788267650409\n",
      "15 : loss = 65.8788267650409\n",
      "16 : loss = 65.8788267650409\n",
      "17 : loss = 65.8788267650409\n",
      "18 : loss = 65.8788267650409\n",
      "19 : loss = 65.8788267650409\n",
      "20 : loss = 65.8788267650409\n",
      "21 : loss = 65.8788267650409\n",
      "22 : loss = 65.8788267650409\n",
      "23 : loss = 65.8788267650409\n",
      "24 : loss = 65.8788267650409\n",
      "25 : loss = 65.8788267650409\n",
      "26 : loss = 65.8788267650409\n",
      "27 : loss = 65.8788267650409\n",
      "28 : loss = 65.8788267650409\n",
      "29 : loss = 65.8788267650409\n",
      "0 : loss = 275.37036171610055\n",
      "1 : loss = 275.37036171610055\n",
      "2 : loss = 275.37036171610055\n",
      "3 : loss = 275.37036171610055\n",
      "4 : loss = 275.37036171610055\n",
      "5 : loss = 275.37036171610055\n",
      "6 : loss = 275.37036171610055\n",
      "7 : loss = 275.37036171610055\n",
      "8 : loss = 275.37036171610055\n",
      "9 : loss = 275.37036171610055\n",
      "10 : loss = 275.37036171610055\n",
      "11 : loss = 275.37036171610055\n",
      "12 : loss = 275.37036171610055\n",
      "13 : loss = 275.37036171610055\n",
      "14 : loss = 275.37036171610055\n",
      "15 : loss = 275.37036171610055\n",
      "16 : loss = 275.37036171610055\n",
      "17 : loss = 275.37036171610055\n",
      "18 : loss = 275.37036171610055\n",
      "19 : loss = 275.37036171610055\n",
      "20 : loss = 275.37036171610055\n",
      "21 : loss = 275.37036171610055\n",
      "22 : loss = 275.37036171610055\n",
      "23 : loss = 275.37036171610055\n",
      "24 : loss = 275.37036171610055\n",
      "25 : loss = 275.37036171610055\n",
      "26 : loss = 275.37036171610055\n",
      "27 : loss = 275.37036171610055\n",
      "28 : loss = 275.37036171610055\n",
      "29 : loss = 275.37036171610055\n",
      "0 : loss = 520.8323274616995\n",
      "1 : loss = 520.8323274616995\n",
      "2 : loss = 520.8323274616995\n",
      "3 : loss = 520.8323274616995\n",
      "4 : loss = 520.8323274616995\n",
      "5 : loss = 520.8323274616995\n",
      "6 : loss = 520.8323274616995\n",
      "7 : loss = 520.8323274616995\n",
      "8 : loss = 520.8323274616995\n",
      "9 : loss = 520.8323274616995\n",
      "10 : loss = 520.8323274616995\n",
      "11 : loss = 520.8323274616995\n",
      "12 : loss = 520.8323274616995\n",
      "13 : loss = 520.8323274616995\n",
      "14 : loss = 520.8323274616995\n",
      "15 : loss = 520.8323274616995\n",
      "16 : loss = 520.8323274616995\n",
      "17 : loss = 520.8323274616995\n",
      "18 : loss = 520.8323274616995\n",
      "19 : loss = 520.8323274616995\n",
      "20 : loss = 520.8323274616995\n",
      "21 : loss = 520.8323274616995\n",
      "22 : loss = 520.8323274616995\n",
      "23 : loss = 520.8323274616995\n",
      "24 : loss = 520.8323274616995\n",
      "25 : loss = 520.8323274616995\n",
      "26 : loss = 520.8323274616995\n",
      "27 : loss = 520.8323274616995\n",
      "28 : loss = 520.8323274616995\n",
      "29 : loss = 520.8323274616995\n",
      "0 : loss = 608.4136001772553\n",
      "1 : loss = 608.4136001772553\n",
      "2 : loss = 608.4136001772553\n",
      "3 : loss = 608.4136001772553\n",
      "4 : loss = 608.4136001772553\n",
      "5 : loss = 608.4136001772553\n",
      "6 : loss = 608.4136001772553\n",
      "7 : loss = 608.4136001772553\n",
      "8 : loss = 608.4136001772553\n",
      "9 : loss = 608.4136001772553\n",
      "10 : loss = 608.4136001772553\n",
      "11 : loss = 608.4136001772553\n",
      "12 : loss = 608.4136001772553\n",
      "13 : loss = 608.4136001772553\n",
      "14 : loss = 608.4136001772553\n",
      "15 : loss = 608.4136001772553\n",
      "16 : loss = 608.4136001772553\n",
      "17 : loss = 608.4136001772553\n",
      "18 : loss = 608.4136001772553\n",
      "19 : loss = 608.4136001772553\n",
      "20 : loss = 608.4136001772553\n",
      "21 : loss = 608.4136001772553\n",
      "22 : loss = 608.4136001772553\n",
      "23 : loss = 608.4136001772553\n",
      "24 : loss = 608.4136001772553\n",
      "25 : loss = 608.4136001772553\n",
      "26 : loss = 608.4136001772553\n",
      "27 : loss = 608.4136001772553\n",
      "28 : loss = 608.4136001772553\n",
      "29 : loss = 608.4136001772553\n",
      "0 : loss = 771.1963785192931\n",
      "1 : loss = 771.1963785192931\n",
      "2 : loss = 771.1963785192931\n",
      "3 : loss = 771.1963785192931\n",
      "4 : loss = 771.1963785192931\n",
      "5 : loss = 771.1963785192931\n",
      "6 : loss = 771.1963785192931\n",
      "7 : loss = 771.1963785192931\n",
      "8 : loss = 771.1963785192931\n",
      "9 : loss = 771.1963785192931\n",
      "10 : loss = 771.1963785192931\n",
      "11 : loss = 771.1963785192931\n",
      "12 : loss = 771.1963785192931\n",
      "13 : loss = 771.1963785192931\n",
      "14 : loss = 771.1963785192931\n",
      "15 : loss = 771.1963785192931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 : loss = 771.1963785192931\n",
      "17 : loss = 771.1963785192931\n",
      "18 : loss = 771.1963785192931\n",
      "19 : loss = 771.1963785192931\n",
      "20 : loss = 771.1963785192931\n",
      "21 : loss = 771.1963785192931\n",
      "22 : loss = 771.1963785192931\n",
      "23 : loss = 771.1963785192931\n",
      "24 : loss = 771.1963785192931\n",
      "25 : loss = 771.1963785192931\n",
      "26 : loss = 771.1963785192931\n",
      "27 : loss = 771.1963785192931\n",
      "28 : loss = 771.1963785192931\n",
      "29 : loss = 771.1963785192931\n",
      "0 : loss = 848.3815653931373\n",
      "1 : loss = 848.3815653931373\n",
      "2 : loss = 848.3815653931373\n",
      "3 : loss = 848.3815653931373\n",
      "4 : loss = 848.3815653931373\n",
      "5 : loss = 848.3815653931373\n",
      "6 : loss = 848.3815653931373\n",
      "7 : loss = 848.3815653931373\n",
      "8 : loss = 848.3815653931373\n",
      "9 : loss = 848.3815653931373\n",
      "10 : loss = 848.3815653931373\n",
      "11 : loss = 848.3815653931373\n",
      "12 : loss = 848.3815653931373\n",
      "13 : loss = 848.3815653931373\n",
      "14 : loss = 848.3815653931373\n",
      "15 : loss = 848.3815653931373\n",
      "16 : loss = 848.3815653931373\n",
      "17 : loss = 848.3815653931373\n",
      "18 : loss = 848.3815653931373\n",
      "19 : loss = 848.3815653931373\n",
      "20 : loss = 848.3815653931373\n",
      "21 : loss = 848.3815653931373\n",
      "22 : loss = 848.3815653931373\n",
      "23 : loss = 848.3815653931373\n",
      "24 : loss = 848.3815653931373\n",
      "25 : loss = 848.3815653931373\n",
      "26 : loss = 848.3815653931373\n",
      "27 : loss = 848.3815653931373\n",
      "28 : loss = 848.3815653931373\n",
      "29 : loss = 848.3815653931373\n",
      "0 : loss = 1014.7619945756613\n",
      "1 : loss = 1014.7619945756613\n",
      "2 : loss = 1014.7619945756613\n",
      "3 : loss = 1014.7619945756613\n",
      "4 : loss = 1014.7619945756613\n",
      "5 : loss = 1014.7619945756613\n",
      "6 : loss = 1014.7619945756613\n",
      "7 : loss = 1014.7619945756613\n",
      "8 : loss = 1014.7619945756613\n",
      "9 : loss = 1014.7619945756613\n",
      "10 : loss = 1014.7619945756613\n",
      "11 : loss = 1014.7619945756613\n",
      "12 : loss = 1014.7619945756613\n",
      "13 : loss = 1014.7619945756613\n",
      "14 : loss = 1014.7619945756613\n",
      "15 : loss = 1014.7619945756613\n",
      "16 : loss = 1014.7619945756613\n",
      "17 : loss = 1014.7619945756613\n",
      "18 : loss = 1014.7619945756613\n",
      "19 : loss = 1014.7619945756613\n",
      "20 : loss = 1014.7619945756613\n",
      "21 : loss = 1014.7619945756613\n",
      "22 : loss = 1014.7619945756613\n",
      "23 : loss = 1014.7619945756613\n",
      "24 : loss = 1014.7619945756613\n",
      "25 : loss = 1014.7619945756613\n",
      "26 : loss = 1014.7619945756613\n",
      "27 : loss = 1014.7619945756613\n",
      "28 : loss = 1014.7619945756613\n",
      "29 : loss = 1014.7619945756613\n",
      "0 : loss = 1113.0958797932944\n",
      "1 : loss = 1113.0958797932944\n",
      "2 : loss = 1113.0958797932944\n",
      "3 : loss = 1113.0958797932944\n",
      "4 : loss = 1113.0958797932944\n",
      "5 : loss = 1113.0958797932944\n",
      "6 : loss = 1113.0958797932944\n",
      "7 : loss = 1113.0958797932944\n",
      "8 : loss = 1113.0958797932944\n",
      "9 : loss = 1113.0958797932944\n",
      "10 : loss = 1113.0958797932944\n",
      "11 : loss = 1113.0958797932944\n",
      "12 : loss = 1113.0958797932944\n",
      "13 : loss = 1113.0958797932944\n",
      "14 : loss = 1113.0958797932944\n",
      "15 : loss = 1113.0958797932944\n",
      "16 : loss = 1113.0958797932944\n",
      "17 : loss = 1113.0958797932944\n",
      "18 : loss = 1113.0958797932944\n",
      "19 : loss = 1113.0958797932944\n",
      "20 : loss = 1113.0958797932944\n",
      "21 : loss = 1113.0958797932944\n",
      "22 : loss = 1113.0958797932944\n",
      "23 : loss = 1113.0958797932944\n",
      "24 : loss = 1113.0958797932944\n",
      "25 : loss = 1113.0958797932944\n",
      "26 : loss = 1113.0958797932944\n",
      "27 : loss = 1113.0958797932944\n",
      "28 : loss = 1113.0958797932944\n",
      "29 : loss = 1113.0958797932944\n",
      "0 : loss = 1286.1725026234037\n",
      "1 : loss = 1286.1725026234037\n",
      "2 : loss = 1286.1725026234037\n",
      "3 : loss = 1286.1725026234037\n",
      "4 : loss = 1286.1725026234037\n",
      "5 : loss = 1286.1725026234037\n",
      "6 : loss = 1286.1725026234037\n",
      "7 : loss = 1286.1725026234037\n",
      "8 : loss = 1286.1725026234037\n",
      "9 : loss = 1286.1725026234037\n",
      "10 : loss = 1286.1725026234037\n",
      "11 : loss = 1286.1725026234037\n",
      "12 : loss = 1286.1725026234037\n",
      "13 : loss = 1286.1725026234037\n",
      "14 : loss = 1286.1725026234037\n",
      "15 : loss = 1286.1725026234037\n",
      "16 : loss = 1286.1725026234037\n",
      "17 : loss = 1286.1725026234037\n",
      "18 : loss = 1286.1725026234037\n",
      "19 : loss = 1286.1725026234037\n",
      "20 : loss = 1286.1725026234037\n",
      "21 : loss = 1286.1725026234037\n",
      "22 : loss = 1286.1725026234037\n",
      "23 : loss = 1286.1725026234037\n",
      "24 : loss = 1286.1725026234037\n",
      "25 : loss = 1286.1725026234037\n",
      "26 : loss = 1286.1725026234037\n",
      "27 : loss = 1286.1725026234037\n",
      "28 : loss = 1286.1725026234037\n",
      "29 : loss = 1286.1725026234037\n",
      "0 : loss = 1363.504463541584\n",
      "1 : loss = 1363.504463541584\n",
      "2 : loss = 1363.504463541584\n",
      "3 : loss = 1363.504463541584\n",
      "4 : loss = 1363.504463541584\n",
      "5 : loss = 1363.504463541584\n",
      "6 : loss = 1363.504463541584\n",
      "7 : loss = 1363.504463541584\n",
      "8 : loss = 1363.504463541584\n",
      "9 : loss = 1363.504463541584\n",
      "10 : loss = 1363.504463541584\n",
      "11 : loss = 1363.504463541584\n",
      "12 : loss = 1363.504463541584\n",
      "13 : loss = 1363.504463541584\n",
      "14 : loss = 1363.504463541584\n",
      "15 : loss = 1363.504463541584\n",
      "16 : loss = 1363.504463541584\n",
      "17 : loss = 1363.504463541584\n",
      "18 : loss = 1363.504463541584\n",
      "19 : loss = 1363.504463541584\n",
      "20 : loss = 1363.504463541584\n",
      "21 : loss = 1363.504463541584\n",
      "22 : loss = 1363.504463541584\n",
      "23 : loss = 1363.504463541584\n",
      "24 : loss = 1363.504463541584\n",
      "25 : loss = 1363.504463541584\n",
      "26 : loss = 1363.504463541584\n",
      "27 : loss = 1363.504463541584\n",
      "28 : loss = 1363.504463541584\n",
      "29 : loss = 1363.504463541584\n",
      "0 : loss = 1505.5993444351432\n",
      "1 : loss = 1505.5993444351432\n",
      "2 : loss = 1505.5993444351432\n",
      "3 : loss = 1505.5993444351432\n",
      "4 : loss = 1505.5993444351432\n",
      "5 : loss = 1505.5993444351432\n",
      "6 : loss = 1505.5993444351432\n",
      "7 : loss = 1505.5993444351432\n",
      "8 : loss = 1505.5993444351432\n",
      "9 : loss = 1505.5993444351432\n",
      "10 : loss = 1505.5993444351432\n",
      "11 : loss = 1505.5993444351432\n",
      "12 : loss = 1505.5993444351432\n",
      "13 : loss = 1505.5993444351432\n",
      "14 : loss = 1505.5993444351432\n",
      "15 : loss = 1505.5993444351432\n",
      "16 : loss = 1505.5993444351432\n",
      "17 : loss = 1505.5993444351432\n",
      "18 : loss = 1505.5993444351432\n",
      "19 : loss = 1505.5993444351432\n",
      "20 : loss = 1505.5993444351432\n",
      "21 : loss = 1505.5993444351432\n",
      "22 : loss = 1505.5993444351432\n",
      "23 : loss = 1505.5993444351432\n",
      "24 : loss = 1505.5993444351432\n",
      "25 : loss = 1505.5993444351432\n",
      "26 : loss = 1505.5993444351432\n",
      "27 : loss = 1505.5993444351432\n",
      "28 : loss = 1505.5993444351432\n",
      "29 : loss = 1505.5993444351432\n",
      "0 : loss = 1591.4908869526655\n",
      "1 : loss = 1591.4908869526655\n",
      "2 : loss = 1591.4908869526655\n",
      "3 : loss = 1591.4908869526655\n",
      "4 : loss = 1591.4908869526655\n",
      "5 : loss = 1591.4908869526655\n",
      "6 : loss = 1591.4908869526655\n",
      "7 : loss = 1591.4908869526655\n",
      "8 : loss = 1591.4908869526655\n",
      "9 : loss = 1591.4908869526655\n",
      "10 : loss = 1591.4908869526655\n",
      "11 : loss = 1591.4908869526655\n",
      "12 : loss = 1591.4908869526655\n",
      "13 : loss = 1591.4908869526655\n",
      "14 : loss = 1591.4908869526655\n",
      "15 : loss = 1591.4908869526655\n",
      "16 : loss = 1591.4908869526655\n",
      "17 : loss = 1591.4908869526655\n",
      "18 : loss = 1591.4908869526655\n",
      "19 : loss = 1591.4908869526655\n",
      "20 : loss = 1591.4908869526655\n",
      "21 : loss = 1591.4908869526655\n",
      "22 : loss = 1591.4908869526655\n",
      "23 : loss = 1591.4908869526655\n",
      "24 : loss = 1591.4908869526655\n",
      "25 : loss = 1591.4908869526655\n",
      "26 : loss = 1591.4908869526655\n",
      "27 : loss = 1591.4908869526655\n",
      "28 : loss = 1591.4908869526655\n",
      "29 : loss = 1591.4908869526655\n",
      "0 : loss = 1751.949012531407\n",
      "1 : loss = 1751.949012531407\n",
      "2 : loss = 1751.949012531407\n",
      "3 : loss = 1751.949012531407\n",
      "4 : loss = 1751.949012531407\n",
      "5 : loss = 1751.949012531407\n",
      "6 : loss = 1751.949012531407\n",
      "7 : loss = 1751.949012531407\n",
      "8 : loss = 1751.949012531407\n",
      "9 : loss = 1751.949012531407\n",
      "10 : loss = 1751.949012531407\n",
      "11 : loss = 1751.949012531407\n",
      "12 : loss = 1751.949012531407\n",
      "13 : loss = 1751.949012531407\n",
      "14 : loss = 1751.949012531407\n",
      "15 : loss = 1751.949012531407\n",
      "16 : loss = 1751.949012531407\n",
      "17 : loss = 1751.949012531407\n",
      "18 : loss = 1751.949012531407\n",
      "19 : loss = 1751.949012531407\n",
      "20 : loss = 1751.949012531407\n",
      "21 : loss = 1751.949012531407\n",
      "22 : loss = 1751.949012531407\n",
      "23 : loss = 1751.949012531407\n",
      "24 : loss = 1751.949012531407\n",
      "25 : loss = 1751.949012531407\n",
      "26 : loss = 1751.949012531407\n",
      "27 : loss = 1751.949012531407\n",
      "28 : loss = 1751.949012531407\n",
      "29 : loss = 1751.949012531407\n",
      "0 : loss = 1850.0661040006346\n",
      "1 : loss = 1850.0661040006346\n",
      "2 : loss = 1850.0661040006346\n",
      "3 : loss = 1850.0661040006346\n",
      "4 : loss = 1850.0661040006346\n",
      "5 : loss = 1850.0661040006346\n",
      "6 : loss = 1850.0661040006346\n",
      "7 : loss = 1850.0661040006346\n",
      "8 : loss = 1850.0661040006346\n",
      "9 : loss = 1850.0661040006346\n",
      "10 : loss = 1850.0661040006346\n",
      "11 : loss = 1850.0661040006346\n",
      "12 : loss = 1850.0661040006346\n",
      "13 : loss = 1850.0661040006346\n",
      "14 : loss = 1850.0661040006346\n",
      "15 : loss = 1850.0661040006346\n",
      "16 : loss = 1850.0661040006346\n",
      "17 : loss = 1850.0661040006346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 : loss = 1850.0661040006346\n",
      "19 : loss = 1850.0661040006346\n",
      "20 : loss = 1850.0661040006346\n",
      "21 : loss = 1850.0661040006346\n",
      "22 : loss = 1850.0661040006346\n",
      "23 : loss = 1850.0661040006346\n",
      "24 : loss = 1850.0661040006346\n",
      "25 : loss = 1850.0661040006346\n",
      "26 : loss = 1850.0661040006346\n",
      "27 : loss = 1850.0661040006346\n",
      "28 : loss = 1850.0661040006346\n",
      "29 : loss = 1850.0661040006346\n",
      "0 : loss = 2000.381614261996\n",
      "1 : loss = 2000.381614261996\n",
      "2 : loss = 2000.381614261996\n",
      "3 : loss = 2000.381614261996\n",
      "4 : loss = 2000.381614261996\n",
      "5 : loss = 2000.381614261996\n",
      "6 : loss = 2000.381614261996\n",
      "7 : loss = 2000.381614261996\n",
      "8 : loss = 2000.381614261996\n",
      "9 : loss = 2000.381614261996\n",
      "10 : loss = 2000.381614261996\n",
      "11 : loss = 2000.381614261996\n",
      "12 : loss = 2000.381614261996\n",
      "13 : loss = 2000.381614261996\n",
      "14 : loss = 2000.381614261996\n",
      "15 : loss = 2000.381614261996\n",
      "16 : loss = 2000.381614261996\n",
      "17 : loss = 2000.381614261996\n",
      "18 : loss = 2000.381614261996\n",
      "19 : loss = 2000.381614261996\n",
      "20 : loss = 2000.381614261996\n",
      "21 : loss = 2000.381614261996\n",
      "22 : loss = 2000.381614261996\n",
      "23 : loss = 2000.381614261996\n",
      "24 : loss = 2000.381614261996\n",
      "25 : loss = 2000.381614261996\n",
      "26 : loss = 2000.381614261996\n",
      "27 : loss = 2000.381614261996\n",
      "28 : loss = 2000.381614261996\n",
      "29 : loss = 2000.381614261996\n",
      "0 : loss = 2078.2868960481514\n",
      "1 : loss = 2078.2868960481514\n",
      "2 : loss = 2078.2868960481514\n",
      "3 : loss = 2078.2868960481514\n",
      "4 : loss = 2078.2868960481514\n",
      "5 : loss = 2078.2868960481514\n",
      "6 : loss = 2078.2868960481514\n",
      "7 : loss = 2078.2868960481514\n",
      "8 : loss = 2078.2868960481514\n",
      "9 : loss = 2078.2868960481514\n",
      "10 : loss = 2078.2868960481514\n",
      "11 : loss = 2078.2868960481514\n",
      "12 : loss = 2078.2868960481514\n",
      "13 : loss = 2078.2868960481514\n",
      "14 : loss = 2078.2868960481514\n",
      "15 : loss = 2078.2868960481514\n",
      "16 : loss = 2078.2868960481514\n",
      "17 : loss = 2078.2868960481514\n",
      "18 : loss = 2078.2868960481514\n",
      "19 : loss = 2078.2868960481514\n",
      "20 : loss = 2078.2868960481514\n",
      "21 : loss = 2078.2868960481514\n",
      "22 : loss = 2078.2868960481514\n",
      "23 : loss = 2078.2868960481514\n",
      "24 : loss = 2078.2868960481514\n",
      "25 : loss = 2078.2868960481514\n",
      "26 : loss = 2078.2868960481514\n",
      "27 : loss = 2078.2868960481514\n",
      "28 : loss = 2078.2868960481514\n",
      "29 : loss = 2078.2868960481514\n",
      "0 : loss = 2212.9876454374544\n",
      "1 : loss = 2212.9876454374544\n",
      "2 : loss = 2212.9876454374544\n",
      "3 : loss = 2212.9876454374544\n",
      "4 : loss = 2212.9876454374544\n",
      "5 : loss = 2212.9876454374544\n",
      "6 : loss = 2212.9876454374544\n",
      "7 : loss = 2212.9876454374544\n",
      "8 : loss = 2212.9876454374544\n",
      "9 : loss = 2212.9876454374544\n",
      "10 : loss = 2212.9876454374544\n",
      "11 : loss = 2212.9876454374544\n",
      "12 : loss = 2212.9876454374544\n",
      "13 : loss = 2212.9876454374544\n",
      "14 : loss = 2212.9876454374544\n",
      "15 : loss = 2212.9876454374544\n",
      "16 : loss = 2212.9876454374544\n",
      "17 : loss = 2212.9876454374544\n",
      "18 : loss = 2212.9876454374544\n",
      "19 : loss = 2212.9876454374544\n",
      "20 : loss = 2212.9876454374544\n",
      "21 : loss = 2212.9876454374544\n",
      "22 : loss = 2212.9876454374544\n",
      "23 : loss = 2212.9876454374544\n",
      "24 : loss = 2212.9876454374544\n",
      "25 : loss = 2212.9876454374544\n",
      "26 : loss = 2212.9876454374544\n",
      "27 : loss = 2212.9876454374544\n",
      "28 : loss = 2212.9876454374544\n",
      "29 : loss = 2212.9876454374544\n",
      "0 : loss = 2316.613042916574\n",
      "1 : loss = 2316.613042916574\n",
      "2 : loss = 2316.613042916574\n",
      "3 : loss = 2316.613042916574\n",
      "4 : loss = 2316.613042916574\n",
      "5 : loss = 2316.613042916574\n",
      "6 : loss = 2316.613042916574\n",
      "7 : loss = 2316.613042916574\n",
      "8 : loss = 2316.613042916574\n",
      "9 : loss = 2316.613042916574\n",
      "10 : loss = 2316.613042916574\n",
      "11 : loss = 2316.613042916574\n",
      "12 : loss = 2316.613042916574\n",
      "13 : loss = 2316.613042916574\n",
      "14 : loss = 2316.613042916574\n",
      "15 : loss = 2316.613042916574\n",
      "16 : loss = 2316.613042916574\n",
      "17 : loss = 2316.613042916574\n",
      "18 : loss = 2316.613042916574\n",
      "19 : loss = 2316.613042916574\n",
      "20 : loss = 2316.613042916574\n",
      "21 : loss = 2316.613042916574\n",
      "22 : loss = 2316.613042916574\n",
      "23 : loss = 2316.613042916574\n",
      "24 : loss = 2316.613042916574\n",
      "25 : loss = 2316.613042916574\n",
      "26 : loss = 2316.613042916574\n",
      "27 : loss = 2316.613042916574\n",
      "28 : loss = 2316.613042916574\n",
      "29 : loss = 2316.613042916574\n",
      "0 : loss = 2476.625119688492\n",
      "1 : loss = 2476.625119688492\n",
      "2 : loss = 2476.625119688492\n",
      "3 : loss = 2476.625119688492\n",
      "4 : loss = 2476.625119688492\n",
      "5 : loss = 2476.625119688492\n",
      "6 : loss = 2476.625119688492\n",
      "7 : loss = 2476.625119688492\n",
      "8 : loss = 2476.625119688492\n",
      "9 : loss = 2476.625119688492\n",
      "10 : loss = 2476.625119688492\n",
      "11 : loss = 2476.625119688492\n",
      "12 : loss = 2476.625119688492\n",
      "13 : loss = 2476.625119688492\n",
      "14 : loss = 2476.625119688492\n",
      "15 : loss = 2476.625119688492\n",
      "16 : loss = 2476.625119688492\n",
      "17 : loss = 2476.625119688492\n",
      "18 : loss = 2476.625119688492\n",
      "19 : loss = 2476.625119688492\n",
      "20 : loss = 2476.625119688492\n",
      "21 : loss = 2476.625119688492\n",
      "22 : loss = 2476.625119688492\n",
      "23 : loss = 2476.625119688492\n",
      "24 : loss = 2476.625119688492\n",
      "25 : loss = 2476.625119688492\n",
      "26 : loss = 2476.625119688492\n",
      "27 : loss = 2476.625119688492\n",
      "28 : loss = 2476.625119688492\n",
      "29 : loss = 2476.625119688492\n",
      "0 : loss = 2567.2991932408495\n",
      "1 : loss = 2567.2991932408495\n",
      "2 : loss = 2567.2991932408495\n",
      "3 : loss = 2567.2991932408495\n",
      "4 : loss = 2567.2991932408495\n",
      "5 : loss = 2567.2991932408495\n",
      "6 : loss = 2567.2991932408495\n",
      "7 : loss = 2567.2991932408495\n",
      "8 : loss = 2567.2991932408495\n",
      "9 : loss = 2567.2991932408495\n",
      "10 : loss = 2567.2991932408495\n",
      "11 : loss = 2567.2991932408495\n",
      "12 : loss = 2567.2991932408495\n",
      "13 : loss = 2567.2991932408495\n",
      "14 : loss = 2567.2991932408495\n",
      "15 : loss = 2567.2991932408495\n",
      "16 : loss = 2567.2991932408495\n",
      "17 : loss = 2567.2991932408495\n",
      "18 : loss = 2567.2991932408495\n",
      "19 : loss = 2567.2991932408495\n",
      "20 : loss = 2567.2991932408495\n",
      "21 : loss = 2567.2991932408495\n",
      "22 : loss = 2567.2991932408495\n",
      "23 : loss = 2567.2991932408495\n",
      "24 : loss = 2567.2991932408495\n",
      "25 : loss = 2567.2991932408495\n",
      "26 : loss = 2567.2991932408495\n",
      "27 : loss = 2567.2991932408495\n",
      "28 : loss = 2567.2991932408495\n",
      "29 : loss = 2567.2991932408495\n",
      "k:  2\n",
      "weight[0] shape:  torch.Size([50, 40000])\n",
      "bias[0] shape:  torch.Size([50, 1])\n",
      "Relu Params[0]:  0.0060149751099436355\n",
      "BN gamma[0]:  1.0143986959665934\n",
      "BN beta[0]:  0.00039869627951913557\n",
      "weight[1] shape:  torch.Size([50, 50])\n",
      "bias[1] shape:  torch.Size([50, 1])\n",
      "Relu Params[1]:  0.01\n",
      "BN gamma[1]:  0.9991703508639939\n",
      "BN beta[1]:  0.00039869627951913557\n",
      "weight[2] shape:  torch.Size([50, 50])\n",
      "bias[2] shape:  torch.Size([50, 1])\n",
      "Relu Params[2]:  0.01\n",
      "BN gamma[2]:  1.00072838332199\n",
      "BN beta[2]:  0.0003996150144270226\n",
      "weight[3] shape:  torch.Size([40000, 50])\n",
      "bias[3] shape:  torch.Size([40000, 1])\n",
      "Relu Params[3]:  0.013613461265533214\n",
      "BN gamma[3]:  1\n",
      "BN beta[3]:  0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-fc799acdc8a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mnn1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# 预测\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mestimateY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestInput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestInput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    layers = (50, 50, 50, 40000)\n",
    "    aFuncs = ('PRelu', 'cos', 'sin', 'PRelu')\n",
    "    normLayer = (True, True, True, False)\n",
    "    epoch = 30\n",
    "    nn1 = DNN(layers, aFuncs)\n",
    "    nn1.setBackProp(PRelu=True, Norm=normLayer)\n",
    "    # 生成权重和偏移\n",
    "    nn1.genParam(40000)\n",
    "    testInput = [None] * 20\n",
    "    targetY = [None] * 20\n",
    "    for i in range(20):\n",
    "        # 生成训练数据\n",
    "        # 所有input全部变型成 m x 1 的形状\n",
    "        testInput[i] = torch.sin(torch.randn((200, 200), dtype=DTYPE['f64'], device=DEVICE[DEVICE_CHOICE]).view(-1, 1))\n",
    "        # 生成目标输出\n",
    "        targetY[i] = ((i+1)*torch.sin(testInput[i]**(i+1))) + ((i+1)*torch.cos((i+1)*testInput[i]-i)) * torch.tanh(testInput[i]+1)\n",
    "    # 训练\n",
    "    for k in range(3):\n",
    "        for i in range(20):      \n",
    "            nn1.train(testInput[i], targetY[i], nanInvestigate=0, epoch=epoch)\n",
    "        print('k: ', k)\n",
    "        nn1.printShape()\n",
    "    # 预测\n",
    "    estimateY = nn1.predict(testInput[19])\n",
    "    \n",
    "    plt.scatter(testInput[0].cpu().numpy().flatten(), targetY[0].cpu().numpy().flatten())\n",
    "    plt.scatter(testInput[0].cpu().numpy().flatten(), estimateY.cpu().numpy().flatten())\n",
    "    plt.show()\n",
    "    nn1.printShape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  tensor([0.2693, 0.7089, 0.9839,  ..., 1.3603, 1.1163, 0.7194], device='cuda:0',\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 测试数据\n",
    "testInput2 = torch.exp(torch.randn((200, 200), dtype=DTYPE['f64'], device=DEVICE[DEVICE_CHOICE]).view(-1, 1))\n",
    "targetY2 = testInput2\n",
    "estimateY2 = nn1.predict(testInput2)\n",
    "plt.scatter(testInput2.cpu().numpy().flatten(), targetY2.cpu().numpy().flatten())\n",
    "plt.scatter(testInput2.cpu().numpy().flatten(), estimateY2.cpu().numpy().flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
